{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from gnn_tracking.utils.loading import TrackingDataset\n",
    "from gnn_tracking.utils.loading import get_loaders\n",
    "from gnn_tracking.metrics.losses import GraphConstructionHingeEmbeddingLoss\n",
    "from gnn_tracking.models.graph_construction import GraphConstructionFCNN\n",
    "from gnn_tracking_hpo.trainable import GCTrainer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = GraphConstructionFCNN(\n",
    "    in_dim=7,\n",
    "    hidden_dim=256,\n",
    "    out_dim=12,\n",
    "    depth=6,\n",
    "    beta=0.4\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from gnn_tracking_hpo.trainable import MetricLearningGraphConstruction\n",
    "\n",
    "# model = MetricLearningGraphConstruction(\n",
    "#     node_indim=7,\n",
    "#     hidden_dim=256,\n",
    "#     h_outdim=12,\n",
    "#     L_gc=6,\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[15:49:14] INFO: DataLoader will load 7743 graphs (out of 7743 available).\u001B[0m\n",
      "\u001B[36m[15:49:14] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v3/part_1/data21000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v3/part_8/data28999_s0.pt\u001B[0m\n",
      "\u001B[32m[15:49:14] INFO: DataLoader will load 5 graphs (out of 1000 available).\u001B[0m\n",
      "\u001B[36m[15:49:14] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v3/part_9/data29000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v3/part_9/data29004_s0.pt\u001B[0m\n",
      "\u001B[36m[15:49:14] DEBUG: Parameters for data loader 'train': {'batch_size': 1, 'num_workers': 1, 'sampler': <torch.utils.data.sampler.RandomSampler object at 0x15214152e7a0>, 'pin_memory': True, 'shuffle': None}\u001B[0m\n",
      "\u001B[36m[15:49:14] DEBUG: Parameters for data loader 'val': {'batch_size': 1, 'num_workers': 1, 'sampler': None, 'pin_memory': True, 'shuffle': False}\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ds = TrackingDataset(\n",
    "    [\n",
    "        f\"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v3/part_{i}\"\n",
    "        for i in range(1, 9)\n",
    "    ]\n",
    ")\n",
    "val_ds = TrackingDataset(\n",
    "    \"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v3/part_9\",\n",
    "    stop=5,\n",
    ")\n",
    "loaders = get_loaders({\"train\": ds, \"val\": val_ds}, batch_size=1, max_sample_size=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "losses = {\n",
    "    \"potential\": (\n",
    "        GraphConstructionHingeEmbeddingLoss(r_emb=1),\n",
    "        {\"attractive\": 1., \"repulsive\": 10.}\n",
    "    )\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[15:52:53 TCNTrainer] INFO: Using device cuda\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = GCTrainer(model=model, loss_functions=losses, loaders=loaders, lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "trainer.loss_functions=losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "def get_loss_avg(trainer):\n",
    "    self = trainer\n",
    "    loader = self.val_loader\n",
    "    assert loader is not None\n",
    "    losses = collections.defaultdict(list)\n",
    "    for _batch_idx, data in enumerate(loader):\n",
    "        data = data.to(self.device)  # noqa: PLW2901\n",
    "        model_output = self.evaluate_model(\n",
    "            data,\n",
    "            mask_pids_reco=False,\n",
    "        )\n",
    "        batch_loss, these_batch_losses, loss_weights = self.get_batch_losses(\n",
    "            model_output\n",
    "        )\n",
    "        for key, value in these_batch_losses.items():\n",
    "            losses[key].append(value.item())\n",
    "        losses[\"total\"].append(batch_loss.item())\n",
    "    print({key: np.mean(value) for key, value in losses.items()})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'potential_attractive': 0.0036825352348387242, 'potential_repulsive': 126.6882110595703, 'total': 1266.8857788085938}\n"
     ]
    }
   ],
   "source": [
    "get_loss_avg(trainer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:52:57 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total= 818.31104, potential_attractive=   0.00231, potential_repulsive= 818.30872 (weighted)\u001B[0m\n",
      "\u001B[36m[15:52:58 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total= 418.91165, potential_attractive=   0.12046, potential_repulsive= 418.79120 (weighted)\u001B[0m\n",
      "\u001B[36m[15:52:59 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total= 206.15721, potential_attractive=   0.16402, potential_repulsive= 205.99319 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:00 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total= 203.25117, potential_attractive=   0.45396, potential_repulsive= 202.79721 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:01 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total= 108.69900, potential_attractive=   0.76063, potential_repulsive= 107.93837 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:02 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=  56.11842, potential_attractive=   1.18358, potential_repulsive=  54.93484 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:03 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=  36.00523, potential_attractive=   1.92717, potential_repulsive=  34.07806 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:04 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=  27.64212, potential_attractive=   3.37555, potential_repulsive=  24.26658 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:04 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=  16.80205, potential_attractive=   4.15510, potential_repulsive=  12.64696 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:05 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=  15.91288, potential_attractive=   4.79494, potential_repulsive=  11.11793 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:53:06 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=  17.82591, potential_attractive=   6.59473, potential_repulsive=  11.23118 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:07 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=  18.65095, potential_attractive=   6.97363, potential_repulsive=  11.67732 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:08 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=  16.54921, potential_attractive=   7.52777, potential_repulsive=   9.02144 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:08 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=  13.83916, potential_attractive=   7.23236, potential_repulsive=   6.60680 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:09 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=  14.46283, potential_attractive=   8.07789, potential_repulsive=   6.38493 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:10 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=  12.85506, potential_attractive=   7.49674, potential_repulsive=   5.35832 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:11 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=  12.65784, potential_attractive=   7.43142, potential_repulsive=   5.22642 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:12 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=  13.80202, potential_attractive=   8.30328, potential_repulsive=   5.49874 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:12 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=  13.09037, potential_attractive=   8.19267, potential_repulsive=   4.89770 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:13 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=  12.88778, potential_attractive=   7.43683, potential_repulsive=   5.45095 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:53:14 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=  11.22644, potential_attractive=   7.53522, potential_repulsive=   3.69122 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:15 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=  12.25827, potential_attractive=   7.92568, potential_repulsive=   4.33259 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:15 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=  12.39034, potential_attractive=   8.16363, potential_repulsive=   4.22672 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:16 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=  11.55571, potential_attractive=   8.11600, potential_repulsive=   3.43970 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:17 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=  11.97191, potential_attractive=   7.92835, potential_repulsive=   4.04355 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:18 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=  11.47773, potential_attractive=   8.05325, potential_repulsive=   3.42447 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:19 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   9.83269, potential_attractive=   6.28549, potential_repulsive=   3.54720 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:19 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   9.47593, potential_attractive=   6.61692, potential_repulsive=   2.85901 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:20 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=  10.06920, potential_attractive=   6.90707, potential_repulsive=   3.16213 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:21 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=  10.72768, potential_attractive=   6.99246, potential_repulsive=   3.73522 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:53:22 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=  10.08748, potential_attractive=   6.94681, potential_repulsive=   3.14067 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:22 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   9.89455, potential_attractive=   6.64109, potential_repulsive=   3.25347 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:23 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   9.36716, potential_attractive=   6.37186, potential_repulsive=   2.99530 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:24 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   9.66916, potential_attractive=   6.87161, potential_repulsive=   2.79755 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:25 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=  10.03361, potential_attractive=   6.65548, potential_repulsive=   3.37813 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:26 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=  10.05525, potential_attractive=   6.89102, potential_repulsive=   3.16423 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:26 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   9.29207, potential_attractive=   6.40844, potential_repulsive=   2.88364 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:27 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   8.41130, potential_attractive=   5.85099, potential_repulsive=   2.56031 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:28 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   9.40220, potential_attractive=   6.40236, potential_repulsive=   2.99984 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:29 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   9.29976, potential_attractive=   5.96133, potential_repulsive=   3.33844 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:53:30 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   7.56673, potential_attractive=   5.40635, potential_repulsive=   2.16037 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:30 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   8.92297, potential_attractive=   5.85161, potential_repulsive=   3.07136 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:31 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   9.02705, potential_attractive=   6.15864, potential_repulsive=   2.86841 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:32 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   8.87975, potential_attractive=   5.88016, potential_repulsive=   2.99959 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:33 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   8.95799, potential_attractive=   6.15981, potential_repulsive=   2.79818 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:33 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   8.26579, potential_attractive=   5.46539, potential_repulsive=   2.80039 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:34 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   8.24854, potential_attractive=   5.69731, potential_repulsive=   2.55123 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:35 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   7.84835, potential_attractive=   5.42212, potential_repulsive=   2.42622 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:36 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   7.76014, potential_attractive=   5.45988, potential_repulsive=   2.30026 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:37 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   8.06016, potential_attractive=   5.79733, potential_repulsive=   2.26283 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:53:38 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   8.14030, potential_attractive=   5.62248, potential_repulsive=   2.51782 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:38 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   7.66676, potential_attractive=   5.15912, potential_repulsive=   2.50765 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:39 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   8.58118, potential_attractive=   5.46332, potential_repulsive=   3.11786 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:40 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   8.96065, potential_attractive=   6.36339, potential_repulsive=   2.59726 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:41 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   8.09953, potential_attractive=   5.69257, potential_repulsive=   2.40696 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:41 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   7.11564, potential_attractive=   5.02568, potential_repulsive=   2.08995 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:42 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   7.24925, potential_attractive=   5.08806, potential_repulsive=   2.16119 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:43 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   8.16792, potential_attractive=   5.64893, potential_repulsive=   2.51899 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:44 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   7.42317, potential_attractive=   5.22250, potential_repulsive=   2.20067 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:44 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   7.80464, potential_attractive=   5.40788, potential_repulsive=   2.39676 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:53:45 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   8.24572, potential_attractive=   5.46714, potential_repulsive=   2.77858 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:46 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   7.29197, potential_attractive=   5.10914, potential_repulsive=   2.18283 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:47 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   8.03029, potential_attractive=   5.34961, potential_repulsive=   2.68068 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:48 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   7.93252, potential_attractive=   5.30310, potential_repulsive=   2.62942 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:48 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   7.35573, potential_attractive=   4.89924, potential_repulsive=   2.45649 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:49 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   7.38958, potential_attractive=   4.86717, potential_repulsive=   2.52241 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:50 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   7.20570, potential_attractive=   5.00719, potential_repulsive=   2.19851 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:51 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   7.36279, potential_attractive=   4.72158, potential_repulsive=   2.64121 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:51 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   7.63187, potential_attractive=   5.26672, potential_repulsive=   2.36515 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:52 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   7.74514, potential_attractive=   5.17147, potential_repulsive=   2.57367 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:53:53 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   7.83291, potential_attractive=   5.41123, potential_repulsive=   2.42168 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:54 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   7.75908, potential_attractive=   5.42151, potential_repulsive=   2.33757 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:54 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   8.23154, potential_attractive=   5.31196, potential_repulsive=   2.91957 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:55 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   7.75652, potential_attractive=   4.92682, potential_repulsive=   2.82970 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:56 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   7.29325, potential_attractive=   5.17998, potential_repulsive=   2.11327 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:57 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   7.76961, potential_attractive=   4.81151, potential_repulsive=   2.95811 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:57 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   7.74960, potential_attractive=   4.90121, potential_repulsive=   2.84838 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:58 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   7.31583, potential_attractive=   5.23604, potential_repulsive=   2.07979 (weighted)\u001B[0m\n",
      "\u001B[36m[15:53:59 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   7.60919, potential_attractive=   5.30996, potential_repulsive=   2.29922 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:00 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   7.03238, potential_attractive=   4.87529, potential_repulsive=   2.15709 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:54:01 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   7.70471, potential_attractive=   5.36117, potential_repulsive=   2.34354 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:02 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   7.24100, potential_attractive=   5.12057, potential_repulsive=   2.12043 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:02 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   8.09612, potential_attractive=   5.68187, potential_repulsive=   2.41425 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:03 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   6.84144, potential_attractive=   5.02087, potential_repulsive=   1.82057 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:04 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   7.04221, potential_attractive=   5.14667, potential_repulsive=   1.89554 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:05 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   7.03155, potential_attractive=   5.11316, potential_repulsive=   1.91839 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:06 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   7.11851, potential_attractive=   4.73585, potential_repulsive=   2.38267 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:06 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   7.26550, potential_attractive=   4.79341, potential_repulsive=   2.47210 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:07 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   6.38163, potential_attractive=   4.49038, potential_repulsive=   1.89125 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:08 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   6.83766, potential_attractive=   4.52612, potential_repulsive=   2.31154 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:54:09 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   6.58762, potential_attractive=   4.45141, potential_repulsive=   2.13621 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:10 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   7.12017, potential_attractive=   5.08596, potential_repulsive=   2.03421 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:10 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   7.28819, potential_attractive=   4.90922, potential_repulsive=   2.37897 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:11 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   7.63168, potential_attractive=   5.01838, potential_repulsive=   2.61330 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:12 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   6.59585, potential_attractive=   4.43260, potential_repulsive=   2.16325 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:13 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   7.09518, potential_attractive=   4.99610, potential_repulsive=   2.09908 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:13 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   7.62395, potential_attractive=   5.34197, potential_repulsive=   2.28198 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:14 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   6.73629, potential_attractive=   4.54526, potential_repulsive=   2.19103 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:15 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   7.77882, potential_attractive=   5.44166, potential_repulsive=   2.33715 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:16 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   7.79649, potential_attractive=   5.70272, potential_repulsive=   2.09376 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:54:16 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   6.49388, potential_attractive=   4.45147, potential_repulsive=   2.04240 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:17 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   7.45974, potential_attractive=   5.11551, potential_repulsive=   2.34423 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:18 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   6.85677, potential_attractive=   4.84192, potential_repulsive=   2.01485 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:19 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   7.05665, potential_attractive=   4.54427, potential_repulsive=   2.51238 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:20 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   7.57129, potential_attractive=   5.03688, potential_repulsive=   2.53441 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:20 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   7.09587, potential_attractive=   5.17600, potential_repulsive=   1.91986 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:21 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   7.33446, potential_attractive=   5.20158, potential_repulsive=   2.13288 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:22 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   7.07504, potential_attractive=   4.54210, potential_repulsive=   2.53294 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:23 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   7.36183, potential_attractive=   5.26393, potential_repulsive=   2.09790 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:24 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   7.29916, potential_attractive=   4.77544, potential_repulsive=   2.52372 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:54:25 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   6.91462, potential_attractive=   4.77714, potential_repulsive=   2.13748 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:25 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   7.34127, potential_attractive=   4.34939, potential_repulsive=   2.99188 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:26 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   6.88492, potential_attractive=   4.77790, potential_repulsive=   2.10701 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:27 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   7.16337, potential_attractive=   5.21079, potential_repulsive=   1.95258 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:28 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   7.99008, potential_attractive=   5.42942, potential_repulsive=   2.56067 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:29 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   7.15331, potential_attractive=   4.93668, potential_repulsive=   2.21663 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:29 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   6.92561, potential_attractive=   4.91335, potential_repulsive=   2.01226 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:30 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   6.99651, potential_attractive=   4.85876, potential_repulsive=   2.13775 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:31 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   7.19887, potential_attractive=   5.25614, potential_repulsive=   1.94273 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:32 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   7.47407, potential_attractive=   4.79478, potential_repulsive=   2.67929 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:54:33 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   6.83217, potential_attractive=   4.69241, potential_repulsive=   2.13976 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:34 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   7.82507, potential_attractive=   5.62566, potential_repulsive=   2.19941 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:34 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   7.59226, potential_attractive=   5.68037, potential_repulsive=   1.91189 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:35 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   7.01645, potential_attractive=   5.38982, potential_repulsive=   1.62663 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:36 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   6.85241, potential_attractive=   4.71925, potential_repulsive=   2.13316 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:37 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   6.63978, potential_attractive=   4.51873, potential_repulsive=   2.12105 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:37 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   6.34754, potential_attractive=   4.45339, potential_repulsive=   1.89415 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:38 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   7.55748, potential_attractive=   5.57298, potential_repulsive=   1.98450 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:39 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   6.41558, potential_attractive=   4.59318, potential_repulsive=   1.82240 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:40 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   6.45856, potential_attractive=   4.54398, potential_repulsive=   1.91458 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:54:41 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   6.89520, potential_attractive=   4.76968, potential_repulsive=   2.12552 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:41 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   7.11268, potential_attractive=   5.25162, potential_repulsive=   1.86106 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:42 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   6.35765, potential_attractive=   4.25720, potential_repulsive=   2.10045 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:43 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   7.32747, potential_attractive=   5.47205, potential_repulsive=   1.85541 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:44 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   6.41876, potential_attractive=   4.41700, potential_repulsive=   2.00176 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:45 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   6.96372, potential_attractive=   5.02965, potential_repulsive=   1.93407 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:45 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   6.98695, potential_attractive=   4.55835, potential_repulsive=   2.42859 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:46 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   6.27100, potential_attractive=   4.43952, potential_repulsive=   1.83149 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:47 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   6.17080, potential_attractive=   4.71856, potential_repulsive=   1.45224 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:48 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   6.57498, potential_attractive=   4.61996, potential_repulsive=   1.95502 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:54:49 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   7.30701, potential_attractive=   5.49596, potential_repulsive=   1.81105 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:49 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   6.86894, potential_attractive=   4.62986, potential_repulsive=   2.23908 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:50 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   6.31210, potential_attractive=   4.53216, potential_repulsive=   1.77994 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:51 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   7.17601, potential_attractive=   5.12340, potential_repulsive=   2.05261 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:52 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   7.12261, potential_attractive=   5.39058, potential_repulsive=   1.73203 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:52 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   6.52335, potential_attractive=   4.39219, potential_repulsive=   2.13117 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:53 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   6.47620, potential_attractive=   4.52918, potential_repulsive=   1.94703 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:54 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   6.96357, potential_attractive=   4.69684, potential_repulsive=   2.26673 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:55 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   6.37432, potential_attractive=   4.71517, potential_repulsive=   1.65916 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:55 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   6.34871, potential_attractive=   4.63573, potential_repulsive=   1.71298 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:54:56 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   6.16772, potential_attractive=   4.36990, potential_repulsive=   1.79782 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:57 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   6.75615, potential_attractive=   4.61470, potential_repulsive=   2.14145 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:58 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   6.84648, potential_attractive=   5.05850, potential_repulsive=   1.78798 (weighted)\u001B[0m\n",
      "\u001B[36m[15:54:59 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   6.07568, potential_attractive=   4.26117, potential_repulsive=   1.81452 (weighted)\u001B[0m\n",
      "\u001B[36m[15:55:00 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   5.69121, potential_attractive=   4.21897, potential_repulsive=   1.47224 (weighted)\u001B[0m\n",
      "\u001B[36m[15:55:00 TCNTrainer] DEBUG: Epoch 0 (   50/100): Total=   6.47741, potential_attractive=   4.61755, potential_repulsive=   1.85986 (weighted)\u001B[0m\n",
      "\u001B[36m[15:55:01 TCNTrainer] DEBUG: Epoch 0 (   60/100): Total=   6.23466, potential_attractive=   4.49060, potential_repulsive=   1.74406 (weighted)\u001B[0m\n",
      "\u001B[36m[15:55:02 TCNTrainer] DEBUG: Epoch 0 (   70/100): Total=   6.47421, potential_attractive=   4.29886, potential_repulsive=   2.17535 (weighted)\u001B[0m\n",
      "\u001B[36m[15:55:03 TCNTrainer] DEBUG: Epoch 0 (   80/100): Total=   6.38998, potential_attractive=   4.56248, potential_repulsive=   1.82750 (weighted)\u001B[0m\n",
      "\u001B[36m[15:55:04 TCNTrainer] DEBUG: Epoch 0 (   90/100): Total=   6.47168, potential_attractive=   5.03380, potential_repulsive=   1.43788 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:55:04 TCNTrainer] DEBUG: Epoch 0 (    0/100): Total=   6.60140, potential_attractive=   4.64044, potential_repulsive=   1.96096 (weighted)\u001B[0m\n",
      "\u001B[36m[15:55:05 TCNTrainer] DEBUG: Epoch 0 (   10/100): Total=   5.97716, potential_attractive=   4.25021, potential_repulsive=   1.72695 (weighted)\u001B[0m\n",
      "\u001B[36m[15:55:06 TCNTrainer] DEBUG: Epoch 0 (   20/100): Total=   6.36089, potential_attractive=   4.38223, potential_repulsive=   1.97866 (weighted)\u001B[0m\n",
      "\u001B[36m[15:55:07 TCNTrainer] DEBUG: Epoch 0 (   30/100): Total=   6.67897, potential_attractive=   4.84540, potential_repulsive=   1.83357 (weighted)\u001B[0m\n",
      "\u001B[36m[15:55:08 TCNTrainer] DEBUG: Epoch 0 (   40/100): Total=   6.96858, potential_attractive=   4.80284, potential_repulsive=   2.16574 (weighted)\u001B[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m):\n\u001B[0;32m----> 2\u001B[0m     \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/training/tcn_trainer.py:351\u001B[0m, in \u001B[0;36mTCNTrainer.train_step\u001B[0;34m(self, max_batches)\u001B[0m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    350\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)  \u001B[38;5;66;03m# noqa: PLW2901\u001B[39;00m\n\u001B[0;32m--> 351\u001B[0m     model_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    352\u001B[0m     batch_loss, batch_losses, loss_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_batch_losses(\n\u001B[1;32m    353\u001B[0m         model_output\n\u001B[1;32m    354\u001B[0m     )\n\u001B[1;32m    355\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad(set_to_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/training/tcn_trainer.py:185\u001B[0m, in \u001B[0;36mTCNTrainer.evaluate_model\u001B[0;34m(self, data, mask_pids_reco)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Evaluate the model on the data and return a dictionary of outputs\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \n\u001B[1;32m    179\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;124;03m    data:\u001B[39;00m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;124;03m    mask_pids_reco: If True, mask out PIDs for non-reconstructables\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    183\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 185\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask_pids_reco:\n\u001B[1;32m    188\u001B[0m     pid_field \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mparticle_id \u001B[38;5;241m*\u001B[39m data\u001B[38;5;241m.\u001B[39mreconstructable\u001B[38;5;241m.\u001B[39mlong()\n",
      "File \u001B[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/models/graph_construction.py:55\u001B[0m, in \u001B[0;36mGraphConstructionFCNN.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m     53\u001B[0m     x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta) \u001B[38;5;241m*\u001B[39m layer(relu(x)) \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta) \u001B[38;5;241m*\u001B[39m x\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m---> 55\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mH\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     56\u001B[0m }\n",
      "File \u001B[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    trainer.train_step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
