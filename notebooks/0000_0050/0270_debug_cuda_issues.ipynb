{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Debugging cuda issues"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from gnn_tracking.models.mlp import MLP\n",
    "from gnn_tracking.training.tcn_trainer import TCNTrainer\n",
    "from gnn_tracking.utils.graph_masks import edge_subgraph\n",
    "from gnn_tracking_hpo.util.paths import add_scripts_path\n",
    "\n",
    "from gnn_tracking.utils.loading import TrackingDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "add_scripts_path()\n",
    "from gnn_tracking_hpo.util.paths import get_config, find_checkpoint\n",
    "from gnn_tracking_hpo.trainable import legacy_config_compatibility\n",
    "\n",
    "from gnn_tracking.utils.dictionaries import subdict_with_prefix_stripped\n",
    "from gnn_tracking_hpo.trainable import TCNTrainable\n",
    "from torch import nn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from tune_ec import ECTrainable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m[19:11:52 gnnt_hpo] DEBUG: Loading config from /home/kl5675/ray_results/ec/ECTrainable_a94b24d1_1_val_batch_size=5,adam_amsgrad=False,adam_beta1=0.9000,adam_beta2=0.9990,adam_eps=0.0000,adam_weight_decay=0_2023-04-12_22-10-45/params.json\u001B[0m\n",
      "\u001B[32m[19:11:52 gnnt_hpo] INFO: I'm running on a node with job ID=47034685\u001B[0m\n",
      "\u001B[33m[19:11:52 gnnt_hpo] WARNING: Dispatcher ID was not set. This should be set by the dispatcher as a class attribute to the trainable.\u001B[0m\n",
      "\u001B[32m[19:11:52 gnnt_hpo] INFO: The ID of my dispatcher is 0\u001B[0m\n",
      "\u001B[36m[19:11:52 SlurmControl] DEBUG: Refreshing control config from /home/kl5675/ray_slurm_control.yaml\u001B[0m\n",
      "\u001B[36m[19:11:52 gnnt_hpo] DEBUG: Got config\n",
      "┌──────────────────────────────────────┬──────────────────────────────────────────┐\n",
      "│ _val_batch_size                      │ 5                                        │\n",
      "│ adam_amsgrad                         │ False                                    │\n",
      "│ adam_beta1                           │ 0.9                                      │\n",
      "│ adam_beta2                           │ 0.999                                    │\n",
      "│ adam_eps                             │ 1e-08                                    │\n",
      "│ adam_weight_decay                    │ 0.0                                      │\n",
      "│ batch_size                           │ 5                                        │\n",
      "│ ec_loss                              │ haughty_focal                            │\n",
      "│ ec_pt_thld                           │ 0.8145532232268194                       │\n",
      "│ focal_alpha                          │ 0.45                                     │\n",
      "│ focal_gamma                          │ 3.5                                      │\n",
      "│ gnn_tracking_experiments_hash        │ a63c12f7995466673e948f3338fc9bbbc9dc7b49 │\n",
      "│ gnn_tracking_hash                    │ c3b6b479b2f54f00b581c82bfd40fa6380ad17d6 │\n",
      "│ lr                                   │ 0.0006402252927288013                    │\n",
      "│ lw_edge                              │ 1.0                                      │\n",
      "│ m_L_ec                               │ 6                                        │\n",
      "│ m_alpha                              │ 0.7588635192855735                       │\n",
      "│ m_hidden_dim                         │ 120                                      │\n",
      "│ m_interaction_edge_dim               │ 120                                      │\n",
      "│ m_interaction_node_dim               │ 120                                      │\n",
      "│ m_residual_type                      │ skip1                                    │\n",
      "│ m_use_intermediate_edge_embeddings   │ True                                     │\n",
      "│ m_use_node_embedding                 │ True                                     │\n",
      "│ n_graphs_train                       │ 247776                                   │\n",
      "│ n_graphs_val                         │ 100                                      │\n",
      "│ optimizer                            │ adam                                     │\n",
      "│ scheduler                            │ None                                     │\n",
      "│ sector                               │ None                                     │\n",
      "│ test                                 │ False                                    │\n",
      "│ train_data_dir                       │ ['/scratch/gpfs/IOJALVO/gnn-tracking/obj │\n",
      "│ training_pt_thld                     │ 0.0                                      │\n",
      "│ training_without_noise               │ False                                    │\n",
      "│ training_without_non_reconstructable │ False                                    │\n",
      "│ val_data_dir                         │ /scratch/gpfs/IOJALVO/gnn-tracking/objec │\n",
      "└──────────────────────────────────────┴──────────────────────────────────────────┘\u001B[0m\n",
      "\u001B[36m[19:11:52 gnnt_hpo] DEBUG: Getting loaders\u001B[0m\n",
      "\u001B[32m[19:11:54] INFO: DataLoader will load 247776 graphs (out of 247776 available).\u001B[0m\n",
      "\u001B[36m[19:11:54] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_1/data21000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_8/data28999_s9.pt\u001B[0m\n",
      "\u001B[32m[19:11:54] INFO: DataLoader will load 100 graphs (out of 32000 available).\u001B[0m\n",
      "\u001B[36m[19:11:54] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_9/data29000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_9/data29003_s11.pt\u001B[0m\n",
      "\u001B[36m[19:11:54] DEBUG: Parameters for data loader 'train': {'batch_size': 5, 'num_workers': 12, 'sampler': <torch.utils.data.sampler.RandomSampler object at 0x150e8e0af8b0>, 'pin_memory': True}\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\u001B[36m[19:11:54] DEBUG: Parameters for data loader 'val': {'batch_size': 5, 'num_workers': 12, 'sampler': None, 'pin_memory': True}\u001B[0m\n",
      "\u001B[36m[19:11:54] DEBUG: Parameters for data loader 'test': {'batch_size': 5, 'num_workers': 1, 'sampler': None, 'pin_memory': True}\u001B[0m\n",
      "\u001B[32m[19:11:54 TCNTrainer] INFO: Using device cuda\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "project = \"ec\"\n",
    "hash = \"a94b24d1\"\n",
    "epoch=-1\n",
    "config = legacy_config_compatibility(get_config(project, hash))\n",
    "trainable = ECTrainable(config)\n",
    "#trainable.load_checkpoint(str(find_checkpoint(project, hash, epoch)), device=\"cuda\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ec = trainable.trainer.model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from gnn_tracking.models.resin import ResIN\n",
    "from torch_geometric.utils import index_to_mask\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "class ModularGraphTCN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        ec: nn.Module,\n",
    "        hc_in: nn.Module,\n",
    "        node_indim: int,\n",
    "        edge_indim: int,\n",
    "        h_dim=5,\n",
    "        e_dim=4,\n",
    "        h_outdim=2,\n",
    "        hidden_dim=40,\n",
    "        feed_edge_weights=False,\n",
    "        ec_threshold=0.5,\n",
    "        mask_orphan_nodes=False,\n",
    "        use_ec_embeddings_for_hc=False,\n",
    "    ):\n",
    "        \"\"\"General form of track condensation network based on preconstructed graphs\n",
    "        with initial step of edge classification (passed as a parameter).\n",
    "\n",
    "        Args:\n",
    "            ec: Edge classifier\n",
    "            hc_in: Track condensor interaction network.\n",
    "            node_indim: Node feature dimension\n",
    "            edge_indim: Edge feature dimension\n",
    "            h_dim: node dimension in the condensation interaction networks\n",
    "            e_dim: edge dimension in the condensation interaction networks\n",
    "            h_outdim: output dimension in clustering space\n",
    "            hidden_dim: width of hidden layers in all perceptrons\n",
    "            feed_edge_weights: whether to feed edge weights to the track condenser\n",
    "            ec_threshold: threshold for edge classification\n",
    "            mask_orphan_nodes: Mask nodes with no connections after EC\n",
    "            use_ec_embeddings_for_hc: Use edge classifier embeddings as input to\n",
    "                track condenser. This currently assumes that h_dim and e_dim are\n",
    "                also the dimensions used in the EC.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        #: Edge classification network\n",
    "        self.ec = ec\n",
    "        #: Track condensation network (usually made up of interaction networks)\n",
    "        self.hc_in = hc_in\n",
    "\n",
    "        node_enc_indim = node_indim\n",
    "        # edge_enc_indim = edge_indim\n",
    "        # if use_ec_embeddings_for_hc:\n",
    "        #     node_enc_indim += h_dim\n",
    "        #     edge_enc_indim += e_dim\n",
    "        # edge_enc_indim += int(feed_edge_weights)\n",
    "\n",
    "        #: Node encoder network for track condenser\n",
    "        self.hc_node_encoder = MLP(\n",
    "            node_enc_indim, h_dim, hidden_dim=hidden_dim, L=2, bias=False\n",
    "        )\n",
    "        #: Edge encoder network for track condenser\n",
    "        # self.hc_edge_encoder = MLP(\n",
    "        #     edge_enc_indim,\n",
    "        #     e_dim,\n",
    "        #     hidden_dim=hidden_dim,\n",
    "        #     L=2,\n",
    "        #     bias=False,\n",
    "        # )\n",
    "\n",
    "        #: NN to predict beta\n",
    "        self.p_beta = MLP(h_dim, 1, hidden_dim, L=3)\n",
    "        #: NN to predict cluster coordinates\n",
    "        self.p_cluster = MLP(h_dim, h_outdim, hidden_dim, L=3)\n",
    "        #: NN to predict track parameters\n",
    "        # self.p_track_param = IN(\n",
    "        #     node_indim=h_dim,\n",
    "        #     edge_indim=e_dim + hc_in.length_concatenated_edge_attrs,\n",
    "        #     node_outdim=1,\n",
    "        #     edge_outdim=1,\n",
    "        #     node_hidden_dim=hidden_dim,\n",
    "        #     edge_hidden_dim=hidden_dim,\n",
    "        # )\n",
    "        # self._feed_edge_weights = feed_edge_weights\n",
    "        # self.threshold = ec_threshold\n",
    "        # self._mask_orphan_nodes = mask_orphan_nodes\n",
    "        # self._use_ec_embeddings_for_hc = use_ec_embeddings_for_hc\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data: Data,\n",
    "    ) -> dict[str, Tensor]:\n",
    "        # ec_result = self.ec(data)\n",
    "        # Assign all EC  output to the data object, so that the cuts\n",
    "        # will be applied automatically when we call `data.subgraph(...)` etc.\n",
    "        # data.edge_weights = ec_result[\"W\"]\n",
    "        # data.ec_node_embedding = ec_result.get(\"node_embedding\", None)\n",
    "        # data.ec_edge_embedding = ec_result.get(\"edge_embedding\", None)\n",
    "        # edge_weights_unmasked = data.edge_weights.clone().detach()\n",
    "        # edge_mask = (data.edge_weights > self.threshold).squeeze()\n",
    "        # data = edge_subgraph(data, edge_mask)\n",
    "\n",
    "        # if self._mask_orphan_nodes:\n",
    "        #     connected_nodes = data.edge_index.flatten().unique()\n",
    "        #     hit_mask = index_to_mask(connected_nodes, size=data.num_nodes)\n",
    "        #     data = data.subgraph(connected_nodes)\n",
    "        # else:\n",
    "        #     hit_mask = torch.ones(\n",
    "        #         data.num_nodes, dtype=torch.bool, device=data.x.device\n",
    "        #     )\n",
    "\n",
    "        # Get the encoded inputs for the track condenser\n",
    "        _edge_attrs = [data.edge_attr]\n",
    "        _xs = [data.x]\n",
    "        # if self._use_ec_embeddings_for_hc:\n",
    "        #     assert data.ec_edge_embedding is not None\n",
    "        #     assert data.ec_node_embedding is not None\n",
    "        #     _edge_attrs.append(data.ec_edge_embedding)\n",
    "        #     _xs.append(data.ec_node_embedding)\n",
    "        # if self._feed_edge_weights:\n",
    "        #     _edge_attrs.append(data.edge_weights)\n",
    "        h_hc = self.relu(self.hc_node_encoder(_xs[0]))\n",
    "        # edge_attr_hc = self.relu(self.hc_edge_encoder(_edge_attrs[0]))\n",
    "\n",
    "        # Run the track condenser\n",
    "        # h_hc, _, _ = self.hc_in(h_hc, data.edge_index, edge_attr_hc)\n",
    "        beta = self.p_beta(h_hc)\n",
    "        # protect against nans\n",
    "        # beta = beta + torch.ones_like(beta) * 10e-9\n",
    "\n",
    "        h = self.p_cluster(h_hc)\n",
    "        # track_params, _ = self.p_track_param(\n",
    "        #     h_hc, data.edge_index, torch.cat(edge_attrs_hc, dim=1)\n",
    "        # )\n",
    "        return {\n",
    "            # \"W\": edge_weights_unmasked,\n",
    "            \"H\": h,\n",
    "            \"B\": beta,\n",
    "            # \"ec_hit_mask\": hit_mask,\n",
    "            # \"ec_edge_mask\": edge_mask,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class PreTrainedECGraphTCN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ec,\n",
    "        *,\n",
    "        node_indim: int,\n",
    "        edge_indim: int,\n",
    "        h_dim=5,\n",
    "        e_dim=4,\n",
    "        h_outdim=2,\n",
    "        hidden_dim=40,\n",
    "        L_hc=3,\n",
    "        alpha_hc: float = 0.5,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"GraphTCN for the use with a pre-trained edge classifier\n",
    "\n",
    "        Args:\n",
    "            ec: Pre-trained edge classifier\n",
    "            node_indim: Node feature dim. Determined by input data.\n",
    "            edge_indim: Edge feature dim. Determined by input data.\n",
    "            h_dim: node dimension after encoding\n",
    "            e_dim: edge dimension after encoding\n",
    "            h_outdim: output dimension in clustering space\n",
    "            hidden_dim: dimension of hidden layers in all MLPs used in the interaction\n",
    "                networks\n",
    "            L_hc: message passing depth for track condenser\n",
    "            alpha_hc: strength of residual connection for multi-layer interaction\n",
    "                networks\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        hc_in = ResIN(\n",
    "            node_dim=h_dim,\n",
    "            edge_dim=e_dim,\n",
    "            object_hidden_dim=hidden_dim,\n",
    "            relational_hidden_dim=hidden_dim,\n",
    "            alpha=alpha_hc,\n",
    "            n_layers=L_hc,\n",
    "        )\n",
    "        self._gtcn = ModularGraphTCN(\n",
    "            ec=ec,\n",
    "            hc_in=hc_in,\n",
    "            node_indim=node_indim,\n",
    "            edge_indim=edge_indim,\n",
    "            h_dim=h_dim,\n",
    "            e_dim=e_dim,\n",
    "            h_outdim=h_outdim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data: Data,\n",
    "    ) -> dict[str, Tensor]:\n",
    "        return self._gtcn.forward(data=data)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Stupid modification that just takes the globally defined EC\n",
    "class PretrainedECTrainable(TCNTrainable):\n",
    "    def get_loss_functions(self) -> dict[str, Any]:\n",
    "        return {\n",
    "            \"potential\": self.get_potential_loss_function(),\n",
    "            # \"background\": self.get_background_loss_function(),\n",
    "            # \"edge\": self.get_edge_loss_function(),\n",
    "        }\n",
    "\n",
    "    def get_trainer(self) -> TCNTrainer:\n",
    "        trainer = super().get_trainer()\n",
    "        trainer.ec_threshold = self.tc[\"m_ec_threshold\"]\n",
    "        return trainer\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "        return PreTrainedECGraphTCN(\n",
    "            ec,\n",
    "            node_indim=7,\n",
    "            edge_indim=4,\n",
    "            **subdict_with_prefix_stripped(self.tc, \"m_\"),\n",
    "        )\n",
    "        # return ec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "import optuna\n",
    "from gnn_tracking_hpo.config import get_metadata, auto_suggest_if_not_fixed\n",
    "from gnn_tracking_hpo.trainable import suggest_default_values\n",
    "\n",
    "\n",
    "def suggest_config(\n",
    "    trial: optuna.Trial,\n",
    "    *,\n",
    "    sector= None,\n",
    "    ec_project: str,\n",
    "    ec_hash: str,\n",
    "    ec_epoch: int = -1,\n",
    "    test=False,\n",
    "    fixed= None,\n",
    ") -> dict[str, Any]:\n",
    "    config = get_metadata(test=test)\n",
    "    config.update(fixed or {})\n",
    "\n",
    "    def d(key, *args, **kwargs):\n",
    "        auto_suggest_if_not_fixed(key, config, trial, *args, **kwargs)\n",
    "\n",
    "    # Definitely Fixed hyperparameters\n",
    "    # --------------------------------\n",
    "\n",
    "    d(\"n_graphs_train\", 247776)\n",
    "    config[\"train_data_dir\"] = [\n",
    "        f\"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_{i}\"\n",
    "        for i in range(1, 9)\n",
    "    ]\n",
    "    d(\n",
    "        \"val_data_dir\",\n",
    "        \"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_9\",\n",
    "    )\n",
    "    d(\"sector\", sector)\n",
    "\n",
    "    d(\"m_mask_orphan_nodes\", True)\n",
    "    d(\"use_ec_embeddings_for_hc\", True)\n",
    "\n",
    "    d(\"ec_project\", ec_project)\n",
    "    d(\"ec_hash\", ec_hash)\n",
    "    d(\"ec_epoch\", ec_epoch)\n",
    "\n",
    "    d(\"batch_size\", 5)\n",
    "\n",
    "    # Keep one fixed because of normalization invariance\n",
    "    d(\"lw_potential_attractive\", 1.0)\n",
    "\n",
    "    d(\"m_hidden_dim\", 120)\n",
    "    d(\"m_h_dim\", 120)\n",
    "    d(\"m_e_dim\", 120)\n",
    "\n",
    "    # Most of the following parameters are fixed based on af5b5461\n",
    "\n",
    "    d(\"attr_pt_thld\", 0.6)\n",
    "    d(\"q_min\", 0.34)\n",
    "    d(\"sb\", 0.09)\n",
    "    d(\"m_alpha_hc\", 0.63)\n",
    "    d(\"lw_background\", 0.0041)\n",
    "    d(\"lw_potential_repulsive\", 0.16)\n",
    "    d(\"repulsive_radius_threshold\", 3.7)\n",
    "    d(\"m_h_outdim\", 7)\n",
    "\n",
    "    # Tuned hyperparameters\n",
    "    # ---------------------\n",
    "\n",
    "    d(\"m_ec_threshold\", 0.1, 0.5)\n",
    "    d(\"lr\", 0.0001, 0.0010)\n",
    "    d(\"m_L_hc\", 3, 5)\n",
    "\n",
    "    suggest_default_values(config, trial, ec=\"fixed\")\n",
    "    print(config)\n",
    "    print(trial.params)\n",
    "    return config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-18 19:11:57,380]\u001B[0m A new study created in memory with name: no-name-341f070d-4ed9-402d-a5a3-11e1255aadb2\u001B[0m\n",
      "\u001B[33m[19:11:57] WARNING: Repository /home/kl5675/Documents/23/git_sync/gnn_tracking/src/gnn_tracking is dirty, commit hash may not be accurate.\u001B[0m\n",
      "\u001B[33m[19:11:57] WARNING: Repository /home/kl5675/Documents/23/git_sync/hpo/src/gnn_tracking_hpo is dirty, commit hash may not be accurate.\u001B[0m\n",
      "\u001B[32m[19:11:57 gnnt_hpo] INFO: I'm running on a node with job ID=47034685\u001B[0m\n",
      "\u001B[33m[19:11:57 gnnt_hpo] WARNING: Dispatcher ID was not set. This should be set by the dispatcher as a class attribute to the trainable.\u001B[0m\n",
      "\u001B[32m[19:11:57 gnnt_hpo] INFO: The ID of my dispatcher is 0\u001B[0m\n",
      "\u001B[36m[19:11:57 SlurmControl] DEBUG: Refreshing control config from /home/kl5675/ray_slurm_control.yaml\u001B[0m\n",
      "\u001B[36m[19:11:57 gnnt_hpo] DEBUG: Got config\n",
      "┌───────────────────────────────┬──────────────────────────────────────────┐\n",
      "│ _val_batch_size               │ 1                                        │\n",
      "│ adam_amsgrad                  │ False                                    │\n",
      "│ adam_beta1                    │ 0.9                                      │\n",
      "│ adam_beta2                    │ 0.999                                    │\n",
      "│ adam_eps                      │ 1e-08                                    │\n",
      "│ adam_weight_decay             │ 0.0                                      │\n",
      "│ attr_pt_thld                  │ 0.6                                      │\n",
      "│ batch_size                    │ 1                                        │\n",
      "│ ec_epoch                      │ -1                                       │\n",
      "│ ec_hash                       │ a94b24d1                                 │\n",
      "│ ec_loss                       │ focal                                    │\n",
      "│ ec_project                    │ ec                                       │\n",
      "│ ec_pt_thld                    │ 0.0                                      │\n",
      "│ edge_indim                    │ 4                                        │\n",
      "│ gnn_tracking_experiments_hash │ 41dda2253ce999deb42d519115dd2e7bd0f3b83c │\n",
      "│ gnn_tracking_hash             │ d765620dde9582e8f229334f60f58bf182ff0e10 │\n",
      "│ lr                            │ 0.0003058865039517711                    │\n",
      "│ lw_background                 │ 0.0041                                   │\n",
      "│ lw_potential_attractive       │ 1.0                                      │\n",
      "│ lw_potential_repulsive        │ 0.16                                     │\n",
      "│ m_L_hc                        │ 4                                        │\n",
      "│ m_alpha_hc                    │ 0.63                                     │\n",
      "│ m_e_dim                       │ 120                                      │\n",
      "│ m_ec_threshold                │ 0.21482499860751353                      │\n",
      "│ m_h_dim                       │ 120                                      │\n",
      "│ m_h_outdim                    │ 7                                        │\n",
      "│ m_hidden_dim                  │ 120                                      │\n",
      "│ m_mask_orphan_nodes           │ True                                     │\n",
      "│ n_graphs_train                │ 1                                        │\n",
      "│ n_graphs_val                  │ 1                                        │\n",
      "│ node_indim                    │ 7                                        │\n",
      "│ optimizer                     │ adam                                     │\n",
      "│ q_min                         │ 0.34                                     │\n",
      "│ repulsive_radius_threshold    │ 3.7                                      │\n",
      "│ sb                            │ 0.09                                     │\n",
      "│ scheduler                     │ None                                     │\n",
      "│ sector                        │ None                                     │\n",
      "│ test                          │ True                                     │\n",
      "│ train_data_dir                │ ['/scratch/gpfs/IOJALVO/gnn-tracking/obj │\n",
      "│ use_ec_embeddings_for_hc      │ True                                     │\n",
      "│ val_data_dir                  │ /scratch/gpfs/IOJALVO/gnn-tracking/objec │\n",
      "└───────────────────────────────┴──────────────────────────────────────────┘\u001B[0m\n",
      "\u001B[36m[19:11:57 gnnt_hpo] DEBUG: Getting loaders\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': True, 'gnn_tracking_hash': 'd765620dde9582e8f229334f60f58bf182ff0e10', 'gnn_tracking_experiments_hash': '41dda2253ce999deb42d519115dd2e7bd0f3b83c', 'n_graphs_train': 1, 'train_data_dir': ['/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_1', '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_2', '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_3', '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_4', '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_5', '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_6', '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_7', '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_8'], 'val_data_dir': '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_9', 'sector': None, 'm_mask_orphan_nodes': True, 'use_ec_embeddings_for_hc': True, 'ec_project': 'ec', 'ec_hash': 'a94b24d1', 'ec_epoch': -1, 'batch_size': 5, 'lw_potential_attractive': 1.0, 'm_hidden_dim': 120, 'm_h_dim': 120, 'm_e_dim': 120, 'attr_pt_thld': 0.6, 'q_min': 0.34, 'sb': 0.09, 'm_alpha_hc': 0.63, 'lw_background': 0.0041, 'lw_potential_repulsive': 0.16, 'repulsive_radius_threshold': 3.7, 'm_h_outdim': 7, 'node_indim': 7, 'edge_indim': 4, 'n_graphs_val': 1, 'ec_pt_thld': 0.0, '_val_batch_size': 1, 'ec_loss': 'focal', 'optimizer': 'adam', 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_eps': 1e-08, 'adam_weight_decay': 0.0, 'adam_amsgrad': False, 'scheduler': None}\n",
      "{'m_ec_threshold': 0.21482499860751353, 'lr': 0.0003058865039517711, 'm_L_hc': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[19:12:00] INFO: DataLoader will load 1 graphs (out of 247776 available).\u001B[0m\n",
      "\u001B[36m[19:12:00] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_1/data21000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_1/data21000_s0.pt\u001B[0m\n",
      "\u001B[32m[19:12:00] INFO: DataLoader will load 1 graphs (out of 32000 available).\u001B[0m\n",
      "\u001B[36m[19:12:00] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_9/data29000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v1/part_9/data29000_s0.pt\u001B[0m\n",
      "\u001B[36m[19:12:00] DEBUG: Parameters for data loader 'train': {'batch_size': 1, 'num_workers': 1, 'sampler': <torch.utils.data.sampler.RandomSampler object at 0x150e837218d0>, 'pin_memory': True}\u001B[0m\n",
      "\u001B[36m[19:12:00] DEBUG: Parameters for data loader 'val': {'batch_size': 1, 'num_workers': 1, 'sampler': None, 'pin_memory': True}\u001B[0m\n",
      "\u001B[36m[19:12:00] DEBUG: Parameters for data loader 'test': {'batch_size': 1, 'num_workers': 1, 'sampler': None, 'pin_memory': True}\u001B[0m\n",
      "\u001B[32m[19:12:00 TCNTrainer] INFO: Using device cuda\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "trial = study.ask()\n",
    "_config = suggest_config(trial=trial, ec_project=project, ec_hash=hash, ec_epoch=epoch, test=True)\n",
    "config = _config | trial.params\n",
    "config[\"batch_size\"] = 1\n",
    "trainable = PretrainedECTrainable(config)\n",
    "trainer = trainable.trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[32m[19:12:02 TCNTrainer] INFO: Epoch  0 (    0/12000): potential_attractive_weighted=   0.00177, potential_repulsive_weighted=  34.21142\u001B[0m\n",
      "\u001B[32m[19:12:02 TCNTrainer] INFO: Epoch  0 (   10/12000): potential_attractive_weighted=   0.02980, potential_repulsive_weighted=  29.64644\u001B[0m\n",
      "\u001B[32m[19:12:03 TCNTrainer] INFO: Epoch  0 (   20/12000): potential_attractive_weighted=   0.35067, potential_repulsive_weighted=  20.73614\u001B[0m\n",
      "\u001B[32m[19:12:03 TCNTrainer] INFO: Epoch  0 (   30/12000): potential_attractive_weighted=   1.69778, potential_repulsive_weighted=  11.59402\u001B[0m\n",
      "\u001B[32m[19:12:03 TCNTrainer] INFO: Epoch  0 (   40/12000): potential_attractive_weighted=   3.89390, potential_repulsive_weighted=   8.58915\u001B[0m\n",
      "\u001B[32m[19:12:03 TCNTrainer] INFO: Epoch  0 (   50/12000): potential_attractive_weighted=   4.05928, potential_repulsive_weighted=   8.62240\u001B[0m\n",
      "\u001B[32m[19:12:03 TCNTrainer] INFO: Epoch  0 (   60/12000): potential_attractive_weighted=   2.97955, potential_repulsive_weighted=   8.70159\u001B[0m\n",
      "\u001B[32m[19:12:04 TCNTrainer] INFO: Epoch  0 (   70/12000): potential_attractive_weighted=   1.88096, potential_repulsive_weighted=   8.34505\u001B[0m\n",
      "\u001B[32m[19:12:04 TCNTrainer] INFO: Epoch  0 (   80/12000): potential_attractive_weighted=   2.86932, potential_repulsive_weighted=   5.47387\u001B[0m\n",
      "\u001B[32m[19:12:04 TCNTrainer] INFO: Epoch  0 (   90/12000): potential_attractive_weighted=   1.51950, potential_repulsive_weighted=   4.84583\u001B[0m\n",
      "\u001B[32m[19:12:04 TCNTrainer] INFO: Epoch  0 (  100/12000): potential_attractive_weighted=   0.99377, potential_repulsive_weighted=   3.91435\u001B[0m\n",
      "\u001B[32m[19:12:04 TCNTrainer] INFO: Epoch  0 (  110/12000): potential_attractive_weighted=   1.01332, potential_repulsive_weighted=   2.90891\u001B[0m\n",
      "\u001B[32m[19:12:05 TCNTrainer] INFO: Epoch  0 (  120/12000): potential_attractive_weighted=   0.67976, potential_repulsive_weighted=   2.75373\u001B[0m\n",
      "\u001B[32m[19:12:05 TCNTrainer] INFO: Epoch  0 (  130/12000): potential_attractive_weighted=   0.85224, potential_repulsive_weighted=   2.11272\u001B[0m\n",
      "\u001B[32m[19:12:05 TCNTrainer] INFO: Epoch  0 (  140/12000): potential_attractive_weighted=   0.68399, potential_repulsive_weighted=   1.97244\u001B[0m\n",
      "Exception in thread Thread-9 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 51, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 307, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/multiprocessing/connection.py\", line 508, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/multiprocessing/connection.py\", line 757, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      2\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPYTORCH_NVFUSER_DISABLE\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/training/tcn_trainer.py:324\u001B[0m, in \u001B[0;36mTCNTrainer.train_step\u001B[0;34m(self, max_batches)\u001B[0m\n\u001B[1;32m    322\u001B[0m n_oom_errors_in_a_row \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    323\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader):\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_batches \u001B[38;5;129;01mand\u001B[39;00m batch_idx \u001B[38;5;241m>\u001B[39m max_batches:\n\u001B[1;32m    326\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    633\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 634\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    636\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    638\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1328\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1329\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1330\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1332\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1285\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1283\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m   1284\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_thread\u001B[38;5;241m.\u001B[39mis_alive():\n\u001B[0;32m-> 1285\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1286\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1287\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[1;32m   1121\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[1;32m   1122\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1130\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[1;32m   1131\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1133\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[1;32m   1135\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1136\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[1;32m   1137\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[1;32m   1138\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/queue.py:180\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    178\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m remaining \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[1;32m    179\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[0;32m--> 180\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnot_empty\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mremaining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get()\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnot_full\u001B[38;5;241m.\u001B[39mnotify()\n",
      "File \u001B[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/threading.py:324\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    322\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 324\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    326\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_NVFUSER_DISABLE\"] = \"\"\n",
    "trainer.train_step()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
