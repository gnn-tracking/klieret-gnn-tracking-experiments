{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from gnn_tracking.models.resin import ResIN\n",
    "from gnn_tracking.models.mlp import MLP\n",
    "from torch_geometric.data import Data\n",
    "from torch import nn, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class GNNEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        node_indim: int,\n",
    "        edge_indim: int,\n",
    "        interaction_node_dim: int = 5,\n",
    "        interaction_edge_dim: int = 4,\n",
    "        out_dim: int,\n",
    "        hidden_dim: int | float = None,\n",
    "        L_ec: int = 3,\n",
    "        alpha: float = 0.5,\n",
    "        residual_type=\"skip1\",\n",
    "        residual_kwargs: dict | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            node_indim: Node feature dim\n",
    "            edge_indim: Edge feature dim\n",
    "            interaction_node_dim: Node dimension for interaction networks.\n",
    "                Defaults to 5 for backward compatibility, but this is probably\n",
    "                not reasonable.\n",
    "            interaction_edge_dim: Edge dimension of interaction networks\n",
    "                Defaults to 4 for backward compatibility, but this is probably\n",
    "                not reasonable.\n",
    "            hidden_dim: width of hidden layers in all perceptrons (edge and node\n",
    "                encoders, hidden dims for MLPs in object and relation networks). If\n",
    "                None: choose as maximum of input/output dims for each MLP separately\n",
    "            L_ec: message passing depth for edge classifier\n",
    "            alpha: strength of residual connection for EC\n",
    "            residual_type: type of residual connection for EC\n",
    "            residual_kwargs: Keyword arguments passed to `ResIN`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if residual_kwargs is None:\n",
    "            residual_kwargs = {}\n",
    "        residual_kwargs[\"collect_hidden_edge_embeds\"] = False\n",
    "        self.relu = nn.ReLU()\n",
    "        self.node_indim = node_indim\n",
    "        self.edge_indim = edge_indim\n",
    "        self.ec_node_encoder = MLP(\n",
    "            node_indim, interaction_node_dim, hidden_dim=hidden_dim, L=2, bias=False\n",
    "        )\n",
    "        self.ec_edge_encoder = MLP(\n",
    "            edge_indim, interaction_edge_dim, hidden_dim=hidden_dim, L=2, bias=False\n",
    "        )\n",
    "        self.ec_resin = ResIN(\n",
    "            node_dim=interaction_node_dim,\n",
    "            edge_dim=interaction_edge_dim,\n",
    "            object_hidden_dim=hidden_dim,\n",
    "            relational_hidden_dim=hidden_dim,\n",
    "            alpha=alpha,\n",
    "            n_layers=L_ec,\n",
    "            residual_type=residual_type,\n",
    "            residual_kwargs=residual_kwargs,\n",
    "        )\n",
    "        self.out_dim = out_dim\n",
    "        self.latent_decoder = MLP(input_size=interaction_edge_dim, output_size=out_dim, hidden_dim=hidden_dim, L=3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        data: Data,\n",
    "    ) -> dict[str, Tensor]:\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        assert x.shape[1] == self.node_indim, x.shape\n",
    "        assert edge_attr.shape[1] == self.edge_indim, edge_attr.shape\n",
    "        h_ec = self.relu(self.ec_node_encoder(x))\n",
    "        edge_attr_ec = self.relu(self.ec_edge_encoder(edge_attr))\n",
    "        h_ec, _, _ = self.ec_resin(\n",
    "            h_ec, edge_index, edge_attr_ec\n",
    "        )\n",
    "        latent = self.latent_decoder(h_ec)\n",
    "        return {\n",
    "            \"H\": latent\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[15:41:07 HPO] INFO: Initializing pre-trained model\u001B[0m\n",
      "\u001B[36m[15:41:07 HPO] DEBUG: Loading config from /home/kl5675/ray_results/gc-hinge-sq-sq-cells/GCTrainable_7dce6aff_24_val_batch_size=1,adam_amsgrad=False,adam_beta1=0.9000,adam_beta2=0.9990,adam_eps=0.0000,adam_weight_decay=_2023-06-08_13-32-02/params.json\u001B[0m\n",
      "\u001B[32m[15:41:07 HPO] INFO: I'm running on a node with job ID=48416495\u001B[0m\n",
      "\u001B[33m[15:41:07 HPO] WARNING: Dispatcher ID was not set. This should be set by the dispatcher as a class attribute to the trainable.\u001B[0m\n",
      "\u001B[32m[15:41:07 HPO] INFO: The ID of my dispatcher is 0\u001B[0m\n",
      "\u001B[36m[15:41:07 SlurmControl] DEBUG: Refreshing control config from /home/kl5675/ray_slurm_control.yaml\u001B[0m\n",
      "\u001B[36m[15:41:07 HPO] DEBUG: Got config\n",
      "┌───────────────────────────────┬──────────────────────────────────────────┐\n",
      "│ _no_data                      │ True                                     │\n",
      "│ _val_batch_size               │ 1                                        │\n",
      "│ adam_amsgrad                  │ False                                    │\n",
      "│ adam_beta1                    │ 0.9                                      │\n",
      "│ adam_beta2                    │ 0.999                                    │\n",
      "│ adam_eps                      │ 1e-08                                    │\n",
      "│ adam_weight_decay             │ 0.0                                      │\n",
      "│ attr_pt_thld                  │ 0.9                                      │\n",
      "│ batch_size                    │ 1                                        │\n",
      "│ ec_loss                       │ focal                                    │\n",
      "│ edge_indim                    │ 4                                        │\n",
      "│ gnn_tracking_experiments_hash │ 3af0c0a889ef312e9d44cec304c91f0642567e4d │\n",
      "│ gnn_tracking_hash             │ c446ebf53a0f05359d09b825d535ab1e30c0388f │\n",
      "│ lr                            │ 0.001                                    │\n",
      "│ lw_potential_attractive       │ 1.0                                      │\n",
      "│ lw_potential_repulsive        │ 0.001953029788887701                     │\n",
      "│ m_beta                        │ 0.4                                      │\n",
      "│ m_depth                       │ 6                                        │\n",
      "│ m_hidden_dim                  │ 512                                      │\n",
      "│ m_out_dim                     │ 8                                        │\n",
      "│ max_edges_per_node            │ 256                                      │\n",
      "│ max_num_neighbors             │ 256                                      │\n",
      "│ max_sample_size               │ 800                                      │\n",
      "│ n_graphs_train                │ 7463                                     │\n",
      "│ n_graphs_val                  │ 5                                        │\n",
      "│ node_indim                    │ 7                                        │\n",
      "│ optimizer                     │ adam                                     │\n",
      "│ p_attr                        │ 2                                        │\n",
      "│ p_rep                         │ 2                                        │\n",
      "│ r_emb                         │ 1.0                                      │\n",
      "│ rs_max_edges                  │ 10000000                                 │\n",
      "│ scheduler                     │ None                                     │\n",
      "│ sector                        │ None                                     │\n",
      "│ test                          │ False                                    │\n",
      "│ train_data_dir                │ ['/scratch/gpfs/IOJALVO/gnn-tracking/obj │\n",
      "│ val_data_dir                  │ /scratch/gpfs/IOJALVO/gnn-tracking/objec │\n",
      "└───────────────────────────────┴──────────────────────────────────────────┘\u001B[0m\n",
      "\u001B[36m[15:41:07 HPO] DEBUG: Getting loaders\u001B[0m\n",
      "\u001B[36m[15:41:07 HPO] DEBUG: Not adding loaders to trainer\u001B[0m\n",
      "\u001B[32m[15:41:07 TCNTrainer] INFO: Using device cuda\u001B[0m\n",
      "\u001B[36m[15:41:08 HPO] DEBUG: Loading checkpoint from /home/kl5675/ray_results/gc-hinge-sq-sq-cells/GCTrainable_7dce6aff_24_val_batch_size=1,adam_amsgrad=False,adam_beta1=0.9000,adam_beta2=0.9990,adam_eps=0.0000,adam_weight_decay=_2023-06-08_13-32-02/checkpoint_000009/checkpoint.pt\u001B[0m\n",
      "\u001B[32m[15:41:08 HPO] INFO: Pre-trained model initialized\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from gnn_tracking_hpo.trainable import GCTrainable\n",
    "from gnn_tracking_hpo.restore import restore_model\n",
    "\n",
    "ml  = restore_model(GCTrainable, tune_dir=\"gc-hinge-sq-sq-cells\", run_hash=\"7dce6aff\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[15:58:51 HPO] INFO: Initializing pre-trained model\u001B[0m\n",
      "\u001B[36m[15:58:51 HPO] DEBUG: Loading config from /home/kl5675/ray_results/gc-hinge-sq-sq-cells/GCTrainable_7dce6aff_24_val_batch_size=1,adam_amsgrad=False,adam_beta1=0.9000,adam_beta2=0.9990,adam_eps=0.0000,adam_weight_decay=_2023-06-08_13-32-02/params.json\u001B[0m\n",
      "\u001B[32m[15:58:51 HPO] INFO: I'm running on a node with job ID=48416495\u001B[0m\n",
      "\u001B[33m[15:58:51 HPO] WARNING: Dispatcher ID was not set. This should be set by the dispatcher as a class attribute to the trainable.\u001B[0m\n",
      "\u001B[32m[15:58:51 HPO] INFO: The ID of my dispatcher is 0\u001B[0m\n",
      "\u001B[36m[15:58:51 SlurmControl] DEBUG: Refreshing control config from /home/kl5675/ray_slurm_control.yaml\u001B[0m\n",
      "\u001B[36m[15:58:51 HPO] DEBUG: Got config\n",
      "┌───────────────────────────────┬──────────────────────────────────────────┐\n",
      "│ _no_data                      │ True                                     │\n",
      "│ _val_batch_size               │ 1                                        │\n",
      "│ adam_amsgrad                  │ False                                    │\n",
      "│ adam_beta1                    │ 0.9                                      │\n",
      "│ adam_beta2                    │ 0.999                                    │\n",
      "│ adam_eps                      │ 1e-08                                    │\n",
      "│ adam_weight_decay             │ 0.0                                      │\n",
      "│ attr_pt_thld                  │ 0.9                                      │\n",
      "│ batch_size                    │ 1                                        │\n",
      "│ ec_loss                       │ focal                                    │\n",
      "│ edge_indim                    │ 4                                        │\n",
      "│ gnn_tracking_experiments_hash │ 3af0c0a889ef312e9d44cec304c91f0642567e4d │\n",
      "│ gnn_tracking_hash             │ c446ebf53a0f05359d09b825d535ab1e30c0388f │\n",
      "│ lr                            │ 0.001                                    │\n",
      "│ lw_potential_attractive       │ 1.0                                      │\n",
      "│ lw_potential_repulsive        │ 0.001953029788887701                     │\n",
      "│ m_beta                        │ 0.4                                      │\n",
      "│ m_depth                       │ 6                                        │\n",
      "│ m_hidden_dim                  │ 512                                      │\n",
      "│ m_out_dim                     │ 8                                        │\n",
      "│ max_edges_per_node            │ 256                                      │\n",
      "│ max_num_neighbors             │ 256                                      │\n",
      "│ max_sample_size               │ 800                                      │\n",
      "│ n_graphs_train                │ 7463                                     │\n",
      "│ n_graphs_val                  │ 5                                        │\n",
      "│ node_indim                    │ 7                                        │\n",
      "│ optimizer                     │ adam                                     │\n",
      "│ p_attr                        │ 2                                        │\n",
      "│ p_rep                         │ 2                                        │\n",
      "│ r_emb                         │ 1.0                                      │\n",
      "│ rs_max_edges                  │ 10000000                                 │\n",
      "│ scheduler                     │ None                                     │\n",
      "│ sector                        │ None                                     │\n",
      "│ test                          │ False                                    │\n",
      "│ train_data_dir                │ ['/scratch/gpfs/IOJALVO/gnn-tracking/obj │\n",
      "│ val_data_dir                  │ /scratch/gpfs/IOJALVO/gnn-tracking/objec │\n",
      "└───────────────────────────────┴──────────────────────────────────────────┘\u001B[0m\n",
      "\u001B[36m[15:58:51 HPO] DEBUG: Getting loaders\u001B[0m\n",
      "\u001B[36m[15:58:51 HPO] DEBUG: Not adding loaders to trainer\u001B[0m\n",
      "\u001B[32m[15:58:51 TCNTrainer] INFO: Using device cuda\u001B[0m\n",
      "\u001B[36m[15:58:51 HPO] DEBUG: Loading checkpoint from /home/kl5675/ray_results/gc-hinge-sq-sq-cells/GCTrainable_7dce6aff_24_val_batch_size=1,adam_amsgrad=False,adam_beta1=0.9000,adam_beta2=0.9990,adam_eps=0.0000,adam_weight_decay=_2023-06-08_13-32-02/checkpoint_000009/checkpoint.pt\u001B[0m\n",
      "\u001B[32m[15:58:51 HPO] INFO: Pre-trained model initialized\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "ml_trainable = restore_model(GCTrainable, tune_dir=\"gc-hinge-sq-sq-cells\", run_hash=\"7dce6aff\", freeze=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from gnn_tracking.models.graph_construction import MLGraphConstruction\n",
    "from gnn_tracking.training.tcn_trainer import TCNTrainer\n",
    "\n",
    "gc = MLGraphConstruction(\n",
    "    ml=ml_trainable,\n",
    "    max_radius=0.8,\n",
    "    max_num_neighbors=64,\n",
    "    use_embedding_features=True,\n",
    "    build_edge_features=True,\n",
    ")\n",
    "\n",
    "class MyTCNTrainer(TCNTrainer):\n",
    "    def data_preproc(self, data: Data) -> Data:\n",
    "        return gc(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[16:02:04] INFO: DataLoader will load 7743 graphs (out of 7743 available).\u001B[0m\n",
      "\u001B[36m[16:02:04] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v5/part_1/data21000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v5/part_8/data28999_s0.pt\u001B[0m\n",
      "\u001B[32m[16:02:04] INFO: DataLoader will load 5 graphs (out of 1000 available).\u001B[0m\n",
      "\u001B[36m[16:02:04] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v5/part_9/data29000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v5/part_9/data29004_s0.pt\u001B[0m\n",
      "\u001B[36m[16:02:04] DEBUG: Parameters for data loader 'train': {'batch_size': 1, 'num_workers': 1, 'sampler': <torch.utils.data.sampler.RandomSampler object at 0x14d04da7dde0>, 'pin_memory': True, 'shuffle': None}\u001B[0m\n",
      "\u001B[36m[16:02:04] DEBUG: Parameters for data loader 'val': {'batch_size': 1, 'num_workers': 1, 'sampler': None, 'pin_memory': True, 'shuffle': False}\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from gnn_tracking.utils.loading import TrackingDataset, get_loaders\n",
    "\n",
    "ds = TrackingDataset(\n",
    "    [\n",
    "        f\"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v5/part_{i}\"\n",
    "        for i in range(1, 9)\n",
    "    ]\n",
    ")\n",
    "val_ds = TrackingDataset(\n",
    "    \"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v5/part_9\", stop=5\n",
    ")\n",
    "loaders = get_loaders({\"train\": ds, \"val\": val_ds}, batch_size=1, max_sample_size=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from gnn_tracking.metrics.losses import GraphConstructionHingeEmbeddingLoss\n",
    "\n",
    "losses = {\n",
    "        \"potential\": (\n",
    "            GraphConstructionHingeEmbeddingLoss(\n",
    "                r_emb=1,\n",
    "                max_num_neighbors=65,\n",
    "                attr_pt_thld=0.9,\n",
    "                p_attr=2,\n",
    "                p_rep=2,\n",
    "            ),\n",
    "            {\n",
    "                \"attractive\": 1,\n",
    "                \"repulsive\": 1e-4,\n",
    "            },\n",
    "        )\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[16:02:06 TCNTrainer] INFO: Using device cuda\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "trainer = MyTCNTrainer(\n",
    "    model=GNNEmbedding(\n",
    "        node_indim=14+8,\n",
    "        edge_indim=(14+8)*2,\n",
    "        interaction_node_dim=128,\n",
    "        interaction_edge_dim=128,\n",
    "        hidden_dim=128,\n",
    "        L_ec=3,\n",
    "        alpha=0.35,\n",
    "        out_dim=8,\n",
    "    ),\n",
    "    loss_functions=losses,\n",
    "    loaders = loaders,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[16:02:09 TCNTrainer] DEBUG: Epoch 1 (    0/100): Total=   0.02466, potential_attractive=   0.01731, potential_repulsive=   0.00735 (weighted)\u001B[0m\n",
      "\u001B[33m[16:02:11 TCNTrainer] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001B[0m\n",
      "\u001B[33m[16:02:14 TCNTrainer] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001B[0m\n",
      "\u001B[33m[16:02:18 TCNTrainer] WARNING: WARNING: ran out of memory (OOM), skipping batch. If this happens frequently, decrease the batch size. Will abort if we get 10 consecutive OOM errors.\u001B[0m\n",
      "\u001B[33m[16:02:19 TCNTrainer] WARNING: Keyboard interrupt\u001B[0m\n",
      "\u001B[32m[16:02:19 TCNTrainer] INFO: Saving checkpoint to 230611_160219_model.pt\u001B[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/training/tcn_trainer.py:609\u001B[0m, in \u001B[0;36mTCNTrainer.train\u001B[0;34m(self, epochs, max_batches)\u001B[0m\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m    608\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 609\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_batches\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_batches\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    610\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m    611\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKeyboard interrupt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/training/tcn_trainer.py:576\u001B[0m, in \u001B[0;36mTCNTrainer.step\u001B[0;34m(self, max_batches)\u001B[0m\n\u001B[1;32m    574\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_epoch \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    575\u001B[0m timer \u001B[38;5;241m=\u001B[39m Timer()\n\u001B[0;32m--> 576\u001B[0m train_losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_batches\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_batches\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m train_time \u001B[38;5;241m=\u001B[39m timer()\n\u001B[1;32m    578\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip_test_during_training:\n",
      "File \u001B[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/training/tcn_trainer.py:354\u001B[0m, in \u001B[0;36mTCNTrainer.train_step\u001B[0;34m(self, max_batches)\u001B[0m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    353\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)  \u001B[38;5;66;03m# noqa: PLW2901\u001B[39;00m\n\u001B[0;32m--> 354\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_preproc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    355\u001B[0m     model_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate_model(data)\n\u001B[1;32m    356\u001B[0m     batch_loss, batch_losses, loss_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_batch_losses(\n\u001B[1;32m    357\u001B[0m         model_output\n\u001B[1;32m    358\u001B[0m     )\n",
      "Cell \u001B[0;32mIn[33], line 14\u001B[0m, in \u001B[0;36mMyTCNTrainer.data_preproc\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdata_preproc\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: Data) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Data:\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/models/graph_construction.py:128\u001B[0m, in \u001B[0;36mMLGraphConstruction.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, data: Data) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Data:\n\u001B[1;32m    127\u001B[0m     mo \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ml(data)\n\u001B[0;32m--> 128\u001B[0m     edge_index \u001B[38;5;241m=\u001B[39m \u001B[43mknn_with_max_radius\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmo\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mH\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_radius\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_max_radius\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_max_num_neighbors\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m     y: T \u001B[38;5;241m=\u001B[39m (  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    132\u001B[0m         data\u001B[38;5;241m.\u001B[39mparticle_id[edge_index[\u001B[38;5;241m0\u001B[39m]] \u001B[38;5;241m==\u001B[39m data\u001B[38;5;241m.\u001B[39mparticle_id[edge_index[\u001B[38;5;241m1\u001B[39m]]\n\u001B[1;32m    133\u001B[0m     )\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_embedding_features:\n",
      "File \u001B[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/models/graph_construction.py:78\u001B[0m, in \u001B[0;36mknn_with_max_radius\u001B[0;34m(x, k, max_radius)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mknn_with_max_radius\u001B[39m(x: T, k: \u001B[38;5;28mint\u001B[39m, max_radius: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[1;32m     68\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"A version of kNN that excludes edges with a distance larger than a given radius.\u001B[39;00m\n\u001B[1;32m     69\u001B[0m \n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m        edge index\u001B[39;00m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 78\u001B[0m     edge_index \u001B[38;5;241m=\u001B[39m \u001B[43mknn_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_radius \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     80\u001B[0m         dists \u001B[38;5;241m=\u001B[39m (x[edge_index[\u001B[38;5;241m0\u001B[39m]] \u001B[38;5;241m-\u001B[39m x[edge_index[\u001B[38;5;241m1\u001B[39m]])\u001B[38;5;241m.\u001B[39mnorm(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[15:58:56 TCNTrainer] INFO: Using device cuda\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "ml_trainer = TCNTrainer(\n",
    "    model=ml_trainable,\n",
    "    loss_functions=losses,\n",
    "    loaders = loaders,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[36m[15:59:01 TCNTrainer] DEBUG: Epoch 1 (    0/100): Total=   0.11372, potential_attractive=   0.11006, potential_repulsive=   0.00366 (weighted)\u001B[0m\n",
      "\u001B[36m[15:59:02 TCNTrainer] DEBUG: Epoch 1 (   10/100): Total=   0.18861, potential_attractive=   0.18473, potential_repulsive=   0.00388 (weighted)\u001B[0m\n",
      "\u001B[36m[15:59:03 TCNTrainer] DEBUG: Epoch 1 (   20/100): Total=   0.04259, potential_attractive=   0.03918, potential_repulsive=   0.00342 (weighted)\u001B[0m\n",
      "\u001B[36m[15:59:04 TCNTrainer] DEBUG: Epoch 1 (   30/100): Total=   0.02023, potential_attractive=   0.01734, potential_repulsive=   0.00290 (weighted)\u001B[0m\n",
      "\u001B[36m[15:59:05 TCNTrainer] DEBUG: Epoch 1 (   40/100): Total=   0.01403, potential_attractive=   0.01095, potential_repulsive=   0.00308 (weighted)\u001B[0m\n",
      "\u001B[36m[15:59:06 TCNTrainer] DEBUG: Epoch 1 (   50/100): Total=   0.01403, potential_attractive=   0.01075, potential_repulsive=   0.00328 (weighted)\u001B[0m\n",
      "\u001B[36m[15:59:06 TCNTrainer] DEBUG: Epoch 1 (   60/100): Total=   0.01402, potential_attractive=   0.01062, potential_repulsive=   0.00340 (weighted)\u001B[0m\n",
      "\u001B[36m[15:59:07 TCNTrainer] DEBUG: Epoch 1 (   70/100): Total=   0.01412, potential_attractive=   0.01051, potential_repulsive=   0.00361 (weighted)\u001B[0m\n",
      "\u001B[36m[15:59:08 TCNTrainer] DEBUG: Epoch 1 (   80/100): Total=   0.01275, potential_attractive=   0.00907, potential_repulsive=   0.00368 (weighted)\u001B[0m\n",
      "\u001B[36m[15:59:09 TCNTrainer] DEBUG: Epoch 1 (   90/100): Total=   0.01181, potential_attractive=   0.00851, potential_repulsive=   0.00330 (weighted)\u001B[0m\n",
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n",
      "\u001B[32m[15:59:10 TCNTrainer] INFO: Results 1: \n",
      "┌────┬─────────────────────────────────────┬────────────────────────────────────────┬───────────┐\n",
      "│    │ Metric                              │ Value                                  │       Std │\n",
      "├────┼─────────────────────────────────────┼────────────────────────────────────────┼───────────┤\n",
      "│    │ _time_test                          │ 0.39024564798455685                    │ nan       │\n",
      "│    │ _time_train                         │ 8.793014655006118                      │ nan       │\n",
      "│    │ lw_potential                        │ {'attractive': 1, 'repulsive': 0.0001} │ nan       │\n",
      "│    │ potential_attractive                │ 0.009449867997318506                   │   0.00256 │\n",
      "│    │ potential_attractive_train          │ 0.0833409140398726                     │ nan       │\n",
      "│    │ potential_attractive_weighted       │ 0.009449867997318506                   │   0.00256 │\n",
      "│    │ potential_attractive_weighted_train │ 0.0833409140398726                     │ nan       │\n",
      "│    │ potential_repulsive                 │ 34.685393524169925                     │   1.88833 │\n",
      "│    │ potential_repulsive_train           │ 35.73381992340088                      │ nan       │\n",
      "│    │ potential_repulsive_weighted        │ 0.0034685393524169924                  │   0.00019 │\n",
      "│    │ potential_repulsive_weighted_train  │ 0.003573381992340088                   │ nan       │\n",
      "│    │ total                               │ 0.01291840709745884                    │   0.00247 │\n",
      "│    │ total_train                         │ 0.08691429508849978                    │ nan       │\n",
      "└────┴─────────────────────────────────────┴────────────────────────────────────────┴───────────┘\u001B[0m\n",
      "\u001B[32m[15:59:10 TCNTrainer] INFO: Saving checkpoint to 230611_155910_model.pt\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "ml_trainer.train(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
