{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from gnn_tracking.metrics.losses.metric_learning import (\n",
    "    GraphConstructionHingeEmbeddingLoss,\n",
    ")\n",
    "\n",
    "sys.path.append(\"/home/kl5675/Documents/23/git_sync/gnn_tracking/tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_losses import td1, get_ml_loss, generate_test_data, MockData\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnn_tracking.preprocessing.point_cloud_builder import get_truth_edge_index\n",
    "\n",
    "def generate_test_data(\n",
    "    n_nodes=1000, n_particles=250, n_x_features=3, rng=None\n",
    ") -> MockData:\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    # no noise\n",
    "    pid = torch.from_numpy(rng.choice(np.arange(n_particles), size=n_nodes))\n",
    "    pid_unique = torch.unique(pid)\n",
    "    # no low pt\n",
    "    pt_pid = 1 + torch.from_numpy(2 * rng.random(len(pid_unique)))\n",
    "    pt = pt_pid[pid]\n",
    "    # no low eta\n",
    "    eta_pid = 0.1 * torch.from_numpy(8 * (rng.random(len(pid_unique)) - 0.5))\n",
    "    eta = eta_pid[pid]\n",
    "    # no non-reco\n",
    "    reco_pid = torch.from_numpy(rng.choice([1.0], size=len(pid_unique)))\n",
    "    reco = reco_pid[pid]\n",
    "\n",
    "    return MockData(\n",
    "        beta=torch.from_numpy(rng.random(n_nodes)),\n",
    "        x=torch.from_numpy(rng.random((n_nodes, n_x_features))),\n",
    "        particle_id=pid,\n",
    "        pred=torch.from_numpy(rng.choice([0.0, 1.0], size=(n_nodes, 1))),\n",
    "        truth=torch.from_numpy(rng.choice([0.0, 1.0], size=(n_nodes, 1))),\n",
    "        pt=pt,\n",
    "        eta=eta,\n",
    "        reconstructable=reco,\n",
    "        batch=torch.zeros_like(reco),\n",
    "        true_edge_index=torch.from_numpy(get_truth_edge_index(pid.numpy())),\n",
    "    )\n",
    "\n",
    "\n",
    "td1 = generate_test_data(50, n_particles=3, rng=np.random.default_rng(seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "td1 = generate_test_data(50, n_particles=3, rng=np.random.default_rng(seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td1.reconstructable = True\n",
    "# all eta is already < 0\n",
    "# td1.particle_id[td1.particle_id == 0] = 1\n",
    "# assert td1.particle_id.min() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_edges.shape=torch.Size([2, 227])\n",
      "rep_edges.shape=torch.Size([2, 1430])\n",
      "norm_att=227.000000001\n",
      "v_att*norm_att=tensor(151.7075, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'attractive': 0.6683151300942156, 'repulsive': 2.247088209688136}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ml_loss(GraphConstructionHingeEmbeddingLoss(rep_normalization=\"n_att_edges\", rep_oi_only=False), td1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_edge_index.shape=torch.Size([2, 227])\n",
      "true_edge_mask.sum()=tensor(227)\n",
      "true_edge.sum()=tensor(425)\n",
      "normalization=tensor(425.)\n",
      "dists[~true_edge].shape=torch.Size([1720])\n",
      "v_att_sum=tensor(271.3724, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'attr': 0.6385233145469406, 'rep': 1.4239822355706957}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ml_loss(OldGraphConstructionHingeEmbeddingLoss(), td1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hinge_loss_components(\n",
    "    *,\n",
    "    x: T,\n",
    "    att_edges: T,\n",
    "    rep_edges: T,\n",
    "    r_emb_hinge: float,\n",
    "    p_attr: float,\n",
    "    p_rep: float,\n",
    "    n_hits_oi: int,\n",
    "    normalization: str,\n",
    ") -> tuple[T, T]:\n",
    "    eps = 1e-9\n",
    "\n",
    "    print(f\"{att_edges.shape=}\")\n",
    "    print(f\"{rep_edges.shape=}\")\n",
    "    dists_att = norm(x[att_edges[0]] - x[att_edges[1]], dim=-1)\n",
    "    norm_att = att_edges.shape[1] + eps\n",
    "    print(f\"{norm_att=}\")\n",
    "    v_att = torch.sum(torch.pow(dists_att, p_attr)) / norm_att\n",
    "    print(f\"{v_att*norm_att=}\")\n",
    "\n",
    "    dists_rep = norm(x[rep_edges[0]] - x[rep_edges[1]], dim=-1)\n",
    "    # There is no \"good\" way to normalize this: The naive way would be\n",
    "    # to normalize to the number of repulsive edges, but this number\n",
    "    # gets smaller and smaller as the training progresses, making the objective\n",
    "    # increasingly harder.\n",
    "    # The maximal number of edges that can be in the radius graph is proportional\n",
    "    # to the number of hits of interest, so we normalize by this number.\n",
    "    if normalization == \"n_rep_edges\":\n",
    "        norm_rep = rep_edges.shape[1] + eps\n",
    "    elif normalization == \"n_hits_oi\":\n",
    "        norm_rep = n_hits_oi + eps\n",
    "    elif normalization == \"n_att_edges\":\n",
    "        norm_rep = att_edges.shape[1] + eps\n",
    "    else:\n",
    "        msg = f\"Normalization {normalization} not recognized.\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Note: Relu necessary for p < 1\n",
    "    v_rep = (\n",
    "        torch.sum(torch.nn.functional.relu(r_emb_hinge - torch.pow(dists_rep, p_rep)))\n",
    "        / norm_rep\n",
    "    )\n",
    "\n",
    "    return v_att, v_rep\n",
    "\n",
    "\n",
    "class GraphConstructionHingeEmbeddingLoss(MultiLossFct, HyperparametersMixin):\n",
    "    # noinspection PyUnusedLocal\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        lw_repulsive: float = 1.0,\n",
    "        r_emb: float = 1.0,\n",
    "        max_num_neighbors: int = 256,\n",
    "        pt_thld: float = 0.9,\n",
    "        max_eta: float = 4.0,\n",
    "        p_attr: float = 1.0,\n",
    "        p_rep: float = 1.0,\n",
    "        rep_normalization: str = \"n_hits_oi\",\n",
    "        rep_oi_only: bool = True,\n",
    "    ):\n",
    "        \"\"\"Loss for graph construction using metric learning.\n",
    "\n",
    "        Args:\n",
    "            lw_repulsive: Loss weight for repulsive part of potential loss\n",
    "            r_emb: Radius for edge construction\n",
    "            max_num_neighbors: Maximum number of neighbors in radius graph building.\n",
    "                See https://github.com/rusty1s/pytorch_cluster#radius-graph\n",
    "            pt_thld: pt threshold for particles of interest\n",
    "            max_eta: maximum eta for particles of interest\n",
    "            p_attr: Power for the attraction term (default 1: linear loss)\n",
    "            p_rep: Power for the repulsion term (default 1: linear loss)\n",
    "            normalization: Normalization for the repulsive term. Can be either\n",
    "                \"n_rep_edges\" (normalizes by the number of repulsive edges < r_emb) or\n",
    "                \"n_hits_oi\" (normalizes by the number of hits of interest) or\n",
    "                \"n_att_edges\" (normalizes by the number of attractive edges of interest)\n",
    "            rep_oi_only: Only consider repulsion between hits if at least one\n",
    "                of the hits is of interest\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def _get_edges(\n",
    "        self, *, x: T, batch: T, true_edge_index: T, mask: T, particle_id: T\n",
    "    ) -> tuple[T, T]:\n",
    "        \"\"\"Returns edge index for graph\"\"\"\n",
    "        near_edges = radius_graph(\n",
    "            x,\n",
    "            r=self.hparams.r_emb,\n",
    "            batch=batch,\n",
    "            loop=False,\n",
    "            max_num_neighbors=self.hparams.max_num_neighbors,\n",
    "        )\n",
    "        # Every edge has to start at a particle of interest, so no special\n",
    "        # case with noise\n",
    "        if self.hparams.rep_oi_only:\n",
    "            rep_edges = near_edges[:, mask[near_edges[0]]]\n",
    "        else:\n",
    "            rep_edges = near_edges\n",
    "        rep_edges = rep_edges[:, particle_id[rep_edges[0]] != particle_id[rep_edges[1]]]\n",
    "        att_edges = true_edge_index[:, mask[true_edge_index[0]]]\n",
    "        return att_edges, rep_edges\n",
    "\n",
    "    # noinspection PyUnusedLocal\n",
    "    def forward(\n",
    "        self,\n",
    "        *,\n",
    "        x: T,\n",
    "        particle_id: T,\n",
    "        batch: T,\n",
    "        true_edge_index: T,\n",
    "        pt: T,\n",
    "        eta: T,\n",
    "        reconstructable: T,\n",
    "        **kwargs,\n",
    "    ) -> MultiLossFctReturn:\n",
    "        if true_edge_index is None:\n",
    "            msg = (\n",
    "                \"True_edge_index must be given and not be None. Are you trying to use \"\n",
    "                \"this loss for OC training? In this case, double check that you are \"\n",
    "                \"properly passing on the true edges.\"\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "        mask = get_good_node_mask_tensors(\n",
    "            pt=pt,\n",
    "            particle_id=particle_id,\n",
    "            reconstructable=reconstructable,\n",
    "            eta=eta,\n",
    "            pt_thld=self.hparams.pt_thld,\n",
    "            max_eta=self.hparams.max_eta,\n",
    "        )\n",
    "        # oi = of interest\n",
    "        n_hits_oi = mask.sum()\n",
    "        att_edges, rep_edges = self._get_edges(\n",
    "            x=x,\n",
    "            batch=batch,\n",
    "            true_edge_index=true_edge_index,\n",
    "            mask=mask,\n",
    "            particle_id=particle_id,\n",
    "        )\n",
    "        attr, rep = _hinge_loss_components(\n",
    "            x=x,\n",
    "            att_edges=att_edges,\n",
    "            rep_edges=rep_edges,\n",
    "            r_emb_hinge=self.hparams.r_emb,\n",
    "            p_attr=self.hparams.p_attr,\n",
    "            p_rep=self.hparams.p_rep,\n",
    "            n_hits_oi=n_hits_oi,\n",
    "            normalization=self.hparams.rep_normalization,\n",
    "        )\n",
    "        losses = {\n",
    "            \"attractive\": attr,\n",
    "            \"repulsive\": rep,\n",
    "        }\n",
    "        weights: dict[str, float] = {\n",
    "            \"attractive\": 1.0,\n",
    "            \"repulsive\": self.hparams.lw_repulsive,\n",
    "        }\n",
    "        extra = {\n",
    "            \"n_hits_oi\": n_hits_oi,\n",
    "            \"n_edges_att\": att_edges.shape[1],\n",
    "            \"n_edges_rep\": rep_edges.shape[1],\n",
    "        }\n",
    "        return MultiLossFctReturn(\n",
    "            loss_dct=losses,\n",
    "            weight_dct=weights,\n",
    "            extra_metrics=extra,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.core.mixins.hparams_mixin import HyperparametersMixin\n",
    "from torch import Tensor as T\n",
    "from torch.linalg import norm\n",
    "from torch_cluster import radius_graph\n",
    "\n",
    "from gnn_tracking.metrics.losses import MultiLossFct, MultiLossFctReturn\n",
    "from gnn_tracking.utils.graph_masks import get_good_node_mask_tensors\n",
    "from torch.nn.functional import relu\n",
    "from torch import nn\n",
    "\n",
    "def _old_hinge_loss_components(\n",
    "    *,\n",
    "    x: T,\n",
    "    edge_index: T,\n",
    "    particle_id: T,\n",
    "    pt: T,\n",
    "    r_emb_hinge: float,\n",
    "    pt_thld: float,\n",
    "    p_attr: float,\n",
    "    p_rep: float,\n",
    ") -> tuple[T, T]:\n",
    "    true_edge = (particle_id[edge_index[0]] == particle_id[edge_index[1]]) & (\n",
    "        particle_id[edge_index[0]] > 0\n",
    "    )\n",
    "    true_high_pt_edge = true_edge & (pt[edge_index[0]] > pt_thld)\n",
    "    dists = norm(x[edge_index[0]] - x[edge_index[1]], dim=-1)\n",
    "    normalization = true_high_pt_edge.sum() + 1e-8\n",
    "    print(f\"{true_edge.sum()=}\")\n",
    "    print(f\"{normalization=}\")\n",
    "    print(f\"{dists[~true_edge].shape=}\")\n",
    "    v_att_sum = torch.sum(\n",
    "        torch.pow(dists[true_high_pt_edge], p_attr)\n",
    "    )\n",
    "    print(f\"{v_att_sum=}\")\n",
    "    return torch.sum(\n",
    "        torch.pow(dists[true_high_pt_edge], p_attr)\n",
    "    ) / normalization, torch.sum(\n",
    "        relu(r_emb_hinge - torch.pow(dists[~true_edge], p_rep)) / normalization\n",
    "    )\n",
    "\n",
    "\n",
    "class OldGraphConstructionHingeEmbeddingLoss(nn.Module, HyperparametersMixin):\n",
    "    # noinspection PyUnusedLocal\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        r_emb=1,\n",
    "        max_num_neighbors: int = 256,\n",
    "        attr_pt_thld: float = 0.9,\n",
    "        p_attr: float = 1,\n",
    "        p_rep: float = 1,\n",
    "    ):\n",
    "        \"\"\"Loss for graph construction using metric learning.\n",
    "\n",
    "        Args:\n",
    "            r_emb: Radius for edge construction\n",
    "            max_num_neighbors: Maximum number of neighbors in radius graph building.\n",
    "                See https://github.com/rusty1s/pytorch_cluster#radius-graph\n",
    "            p_attr: Power for the attraction term (default 1: linear loss)\n",
    "            p_rep: Power for the repulsion term (default 1: linear loss)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def _build_graph(self, x: T, batch: T, true_edge_index: T, pt: T) -> T:\n",
    "        true_edge_mask = pt[true_edge_index[0]] > self.hparams.attr_pt_thld\n",
    "        near_edges = radius_graph(\n",
    "            x,\n",
    "            r=self.hparams.r_emb,\n",
    "            batch=batch,\n",
    "            loop=False,\n",
    "            max_num_neighbors=self.hparams.max_num_neighbors,\n",
    "        )\n",
    "        print(f\"{true_edge_index.shape=}\")\n",
    "        print(f\"{true_edge_mask.sum()=}\")\n",
    "        # return torch.unique(\n",
    "        #     torch.cat([true_edge_index[:, true_edge_mask], near_edges], dim=-1), dim=-1\n",
    "        # )\n",
    "        return torch.unique(torch.cat([true_edge_index[:, true_edge_mask], near_edges], dim=-1), dim=-1)\n",
    "    # noinspection PyUnusedLocal\n",
    "    def forward(\n",
    "        self, *, x: T, particle_id: T, batch: T, true_edge_index: T, pt: T, **kwargs\n",
    "    ) -> dict[str, T]:\n",
    "        edge_index = self._build_graph(\n",
    "            x=x, batch=batch, true_edge_index=true_edge_index, pt=pt\n",
    "        )\n",
    "        attr, rep = _old_hinge_loss_components(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            particle_id=particle_id,\n",
    "            r_emb_hinge=self.hparams.r_emb,\n",
    "            pt=pt,\n",
    "            pt_thld=self.hparams.attr_pt_thld,\n",
    "            p_attr=self.hparams.p_attr,\n",
    "            p_rep=self.hparams.p_rep,\n",
    "        )\n",
    "        losses = {\n",
    "            \"attr\": attr,\n",
    "            \"rep\": rep,\n",
    "        }\n",
    "        return MultiLossFctReturn(\n",
    "            loss_dct=losses,\n",
    "            weight_dct={\"attr\": 1, \"rep\": 1},\n",
    "            extra_metrics={},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_edge_mask = td1.pt[td1.true_edge_index[0]] > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_edges = radius_graph(\n",
    "    td1.x,\n",
    "    r=1,\n",
    "    batch=td1.batch,\n",
    "    loop=False,\n",
    "    max_num_neighbors=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2116])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 227])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td1.true_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(torch.tensor([[1, 2, 3], [0, 0, 0]]), dim=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(396)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((td1.particle_id[near_edges[0]] == td1.particle_id[near_edges[1]]) & (td1.particle_id[near_edges[0]] > 0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 227])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td1.true_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei = torch.unique(torch.sort(torch.cat([td1.true_edge_index[:, true_edge_mask], near_edges], dim=-1), dim=0).values, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_edge = (td1.particle_id[ei[0]] == td1.particle_id[ei[1]]) & (td1.particle_id[ei[0]] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(227)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_edge.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 227])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td1.true_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(torch.tensor([\n",
    "    [0, 2],\n",
    "    [1, 1]\n",
    "]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 103891)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pids = np.random.randint(0, 3, 1000)\n",
    "get_truth_edge_index(random_pids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103891"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for i in np.unique(random_pids):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    count = (random_pids == i).sum()\n",
    "    total += count * (count-1) // 2\n",
    "total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truth_edge_index(pids: A) -> A:\n",
    "    \"\"\"Get edge index for all edges, connecting hits of the same `particle_id`.\n",
    "    To save space, only edges in one direction are returned.\n",
    "    \"\"\"\n",
    "    upids = np.unique(pids[pids > 0])\n",
    "    mask: A = pids.reshape(1, -1) == upids.reshape(-1, 1)  # type: ignore\n",
    "    edges = []\n",
    "    for i_particle in range(mask.shape[0]):\n",
    "        indices = np.nonzero(mask[i_particle])[0]\n",
    "        if len(indices) < 2:\n",
    "            continue\n",
    "        edges += list(itertools.combinations(indices, 2))\n",
    "    return np.array(edges).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
