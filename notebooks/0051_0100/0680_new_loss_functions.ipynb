{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnn_tracking.metrics.losses.oc import CondensationLossTiger, CondensationLossRG\n",
    "from gnn_tracking.training.callbacks import PrintValidationMetrics\n",
    "from gnn_tracking.training.tc import TCModule\n",
    "from gnn_tracking.models.graph_construction import MLGraphConstructionFromChkpt\n",
    "from gnn_tracking.models.track_condensation_networks import PreTrainedECGraphTCN\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ml_chkpt_path=Path(\"/home/kl5675/Documents/23/git_sync/hyperparameter_optimization2/scripts/full_detector/lightning_logs/merciful-reindeer-of-coffee/checkpoints/epoch=79-step=72000.compat.ckpt\")\n",
    "ckpt = torch.load(ml_chkpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 136,\n",
       " 'global_step': 1060791,\n",
       " 'pytorch-lightning_version': '2.0.4',\n",
       " 'state_dict': OrderedDict([('model._latent_normalization',\n",
       "               tensor([0.3039], device='cuda:0')),\n",
       "              ('model._encoder.weight',\n",
       "               tensor([[ 4.4126e-01, -4.6154e-01, -7.6596e-02,  ...,  5.4795e+00,\n",
       "                         4.1984e-01,  7.8441e-01],\n",
       "                       [-6.8870e-01,  2.7098e+00,  1.3297e-01,  ..., -2.9176e+00,\n",
       "                        -3.2144e-01,  3.9957e-03],\n",
       "                       [-3.7865e-01, -2.4479e-02, -6.0885e-02,  ..., -5.5328e-01,\n",
       "                        -5.2481e-01,  5.3502e-01],\n",
       "                       ...,\n",
       "                       [ 1.3068e-01,  2.2458e+00, -6.6728e-02,  ..., -8.7599e+00,\n",
       "                        -3.5665e-02, -2.5705e-01],\n",
       "                       [ 3.0357e-03,  4.7783e-01,  4.2391e-03,  ...,  2.2119e+00,\n",
       "                         1.8651e+00, -1.1115e-02],\n",
       "                       [ 2.0886e-02, -7.2944e+00,  1.6007e-01,  ...,  1.6530e+00,\n",
       "                         5.0335e-01, -3.8901e-01]], device='cuda:0')),\n",
       "              ('model._decoder.weight',\n",
       "               tensor([[ 0.0503, -0.1265,  0.0089,  ...,  0.0205, -0.0462, -0.0769],\n",
       "                       [ 0.0569, -0.0601, -0.1495,  ..., -0.1851, -0.0577,  0.9086],\n",
       "                       [ 0.0604, -0.0017,  0.1160,  ...,  0.1151,  0.0789, -0.1420],\n",
       "                       ...,\n",
       "                       [ 0.1128, -0.0094, -0.2473,  ..., -0.2767, -0.1820,  0.4828],\n",
       "                       [ 0.1138, -0.0218, -0.0507,  ..., -0.0397, -0.1186, -0.2684],\n",
       "                       [-0.1445, -0.0351, -0.0530,  ..., -0.0762,  0.0306,  0.5686]],\n",
       "                      device='cuda:0')),\n",
       "              ('model._layers.0.weight',\n",
       "               tensor([[-0.0305, -0.2023, -0.2387,  ..., -0.3112,  0.9422,  0.2127],\n",
       "                       [-1.2743, -0.1578,  1.0151,  ...,  0.1486, -0.1205, -0.0797],\n",
       "                       [-0.1559, -0.0256,  0.0840,  ...,  0.0336, -0.1781,  0.0216],\n",
       "                       ...,\n",
       "                       [-0.1118,  0.1744,  0.0814,  ...,  0.2709, -0.5720,  0.1537],\n",
       "                       [-0.0123,  0.0602,  0.1854,  ..., -0.2033,  1.0693,  0.0657],\n",
       "                       [-0.4012, -0.0280, -0.0646,  ...,  0.0773, -0.0931,  0.1444]],\n",
       "                      device='cuda:0')),\n",
       "              ('model._layers.1.weight',\n",
       "               tensor([[-0.4721, -0.0914,  0.0427,  ..., -0.1406,  0.6023, -0.0145],\n",
       "                       [-0.0302,  0.0535, -0.6407,  ...,  0.6044, -0.5739, -0.4667],\n",
       "                       [-0.0675, -0.0270,  0.1119,  ...,  0.1694, -0.0021,  0.1983],\n",
       "                       ...,\n",
       "                       [-0.0109,  0.2328, -0.0282,  ..., -0.3412, -0.1374, -0.5946],\n",
       "                       [-0.0647, -0.0353,  0.0596,  ..., -0.0758,  0.5032,  0.1033],\n",
       "                       [ 0.0135,  0.0101,  0.1713,  ..., -0.2560, -0.1426,  0.3377]],\n",
       "                      device='cuda:0')),\n",
       "              ('model._layers.2.weight',\n",
       "               tensor([[-0.2713, -0.0244, -0.1799,  ..., -0.1163,  0.2146,  0.1108],\n",
       "                       [-0.2581,  0.1384,  0.2491,  ...,  0.0103, -0.3473,  0.0258],\n",
       "                       [ 0.0951, -0.1082,  0.0964,  ..., -0.0756, -0.0600, -0.3583],\n",
       "                       ...,\n",
       "                       [-0.0402,  0.0544,  0.1903,  ...,  0.0640, -0.2387, -0.2001],\n",
       "                       [ 0.2586, -0.0546, -0.1165,  ..., -0.1976,  0.2959,  0.1074],\n",
       "                       [-0.1123,  0.1453,  0.0643,  ..., -0.1534, -0.8360,  0.1494]],\n",
       "                      device='cuda:0')),\n",
       "              ('model._layers.3.weight',\n",
       "               tensor([[-0.8415, -0.1768,  0.0709,  ..., -1.0873, -0.1831,  0.4850],\n",
       "                       [-0.3133, -0.0595, -0.0229,  ...,  0.0724,  0.8832,  0.5613],\n",
       "                       [ 0.1151,  0.1704, -0.1887,  ...,  0.0667,  0.1123, -0.1037],\n",
       "                       ...,\n",
       "                       [ 0.1128, -0.0815, -0.2018,  ...,  0.1446, -0.0611,  0.1143],\n",
       "                       [ 0.1453, -0.1586,  0.0421,  ..., -0.1766, -0.4363, -0.0360],\n",
       "                       [-0.3972, -0.0447, -0.0724,  ..., -0.1764, -0.3472, -0.4544]],\n",
       "                      device='cuda:0')),\n",
       "              ('model._layers.4.weight',\n",
       "               tensor([[-0.1233,  0.6622,  0.2303,  ...,  0.1480,  0.3444, -1.0260],\n",
       "                       [-0.1935, -0.3127,  0.1452,  ..., -0.2712, -0.0315,  0.5468],\n",
       "                       [ 0.0352,  0.7399,  0.1139,  ...,  0.8520, -0.3231, -0.7103],\n",
       "                       ...,\n",
       "                       [-0.0761, -0.0227,  0.3913,  ..., -0.1932, -0.4190, -0.3104],\n",
       "                       [ 0.2268,  0.2893,  0.1048,  ...,  0.6986,  0.2809,  0.2500],\n",
       "                       [ 0.1153,  0.2827, -0.0711,  ..., -0.6600,  0.0330,  0.2231]],\n",
       "                      device='cuda:0'))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 1060791},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 1060791,\n",
       "     'completed': 1060791,\n",
       "     'started': 1060791,\n",
       "     'processed': 1060791},\n",
       "    'current': {'ready': 7743,\n",
       "     'completed': 7743,\n",
       "     'started': 7743,\n",
       "     'processed': 7743},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 137, 'completed': 137},\n",
       "    'current': {'ready': 1, 'completed': 1}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 1060791,\n",
       "       'completed': 1060791},\n",
       "      'current': {'ready': 7743, 'completed': 7743}},\n",
       "     'zero_grad': {'total': {'ready': 1060791,\n",
       "       'completed': 1060791,\n",
       "       'started': 1060791},\n",
       "      'current': {'ready': 7743, 'completed': 7743, 'started': 7743}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 50,\n",
       "     'completed': 50,\n",
       "     'started': 50,\n",
       "     'processed': 50},\n",
       "    'current': {'ready': 50, 'completed': 50, 'started': 50, 'processed': 50},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 137,\n",
       "     'completed': 136,\n",
       "     'started': 137,\n",
       "     'processed': 137},\n",
       "    'current': {'ready': 137,\n",
       "     'completed': 136,\n",
       "     'started': 137,\n",
       "     'processed': 137}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"EarlyStopping{'monitor': 'n_edges_frac_segment50_95', 'mode': 'min'}\": {'wait_count': 0,\n",
       "   'stopped_epoch': 0,\n",
       "   'best_score': tensor(197442.9531, device='cuda:0'),\n",
       "   'patience': 20},\n",
       "  \"ModelCheckpoint{'monitor': 'n_edges_frac_segment50_95', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': 'n_edges_frac_segment50_95',\n",
       "   'best_model_score': tensor(197442.9531, device='cuda:0'),\n",
       "   'best_model_path': './lightning_logs/quiet-origami-prawn/checkpoints/epoch=136-n_edges_frac_segment50_95=197442.95.ckpt',\n",
       "   'current_score': tensor(197442.9531, device='cuda:0'),\n",
       "   'dirpath': './lightning_logs/quiet-origami-prawn/checkpoints',\n",
       "   'best_k_models': {'./lightning_logs/quiet-origami-prawn/checkpoints/epoch=136-n_edges_frac_segment50_95=197442.95.ckpt': tensor(197442.9531, device='cuda:0')},\n",
       "   'kth_best_model_path': './lightning_logs/quiet-origami-prawn/checkpoints/epoch=136-n_edges_frac_segment50_95=197442.95.ckpt',\n",
       "   'kth_value': tensor(197442.9531, device='cuda:0'),\n",
       "   'last_model_path': './lightning_logs/quiet-origami-prawn/checkpoints/last.ckpt'}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(1060791.),\n",
       "     'exp_avg': tensor([-0.0088], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([0.0576], device='cuda:0')},\n",
       "    1: {'step': tensor(1060791.),\n",
       "     'exp_avg': tensor([[-1.2931e-03, -1.3411e-04,  6.0282e-02,  ..., -7.2908e-06,\n",
       "              -1.2090e-04, -9.2993e-05],\n",
       "             [-6.9899e-03, -3.4522e-05, -4.9506e-03,  ...,  8.6151e-06,\n",
       "               8.5138e-05, -1.2371e-04],\n",
       "             [-2.6572e-03,  1.5444e-04,  2.1886e-02,  ..., -1.8446e-05,\n",
       "               2.7033e-04,  7.8273e-06],\n",
       "             ...,\n",
       "             [ 1.6714e-02, -7.6006e-05, -2.6642e-01,  ...,  1.0677e-05,\n",
       "              -2.6682e-04, -4.4539e-04],\n",
       "             [ 3.7436e-02, -4.9216e-04, -3.9911e-02,  ..., -4.7045e-05,\n",
       "               3.9311e-05, -1.2674e-03],\n",
       "             [ 5.3096e-03, -3.0995e-05, -2.0983e-02,  ...,  1.7302e-05,\n",
       "               1.0103e-04,  2.1570e-05]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[3.0650e-03, 6.1045e-07, 8.1744e-02,  ..., 2.8132e-08, 7.5928e-07,\n",
       "              6.1324e-07],\n",
       "             [2.3500e-03, 5.2402e-07, 4.2606e-01,  ..., 1.1626e-08, 4.8099e-07,\n",
       "              4.3741e-07],\n",
       "             [1.2699e-04, 5.1241e-07, 2.8672e-02,  ..., 1.4430e-08, 3.9947e-07,\n",
       "              3.3073e-07],\n",
       "             ...,\n",
       "             [2.0556e-02, 1.8827e-06, 1.5563e+00,  ..., 3.3327e-08, 2.5629e-06,\n",
       "              2.7478e-06],\n",
       "             [1.3813e-01, 1.4433e-05, 1.3234e+00,  ..., 1.2089e-06, 2.3484e-05,\n",
       "              1.3669e-05],\n",
       "             [3.5095e-03, 2.0596e-07, 6.1265e-01,  ..., 6.3186e-09, 2.2050e-07,\n",
       "              2.0139e-07]], device='cuda:0')},\n",
       "    2: {'step': tensor(1060791.),\n",
       "     'exp_avg': tensor([[ 3.7912e-05,  1.1523e-03, -5.2766e-04,  ..., -2.3906e-04,\n",
       "              -2.4176e-04,  3.2499e-03],\n",
       "             [-8.1441e-04, -2.7742e-04,  3.7731e-04,  ...,  2.1077e-03,\n",
       "              -1.5832e-04, -3.6040e-03],\n",
       "             [ 6.8790e-04, -6.7917e-05, -1.4090e-04,  ..., -2.8462e-05,\n",
       "               2.7650e-04, -6.9390e-04],\n",
       "             ...,\n",
       "             [ 2.3240e-04,  4.9546e-04, -1.7636e-04,  ...,  1.9722e-03,\n",
       "               4.0339e-04,  4.7535e-03],\n",
       "             [-1.8344e-04,  1.9255e-04, -3.9923e-04,  ..., -2.2376e-03,\n",
       "               1.0778e-03, -7.1937e-04],\n",
       "             [-1.1426e-03,  6.6417e-04, -3.4943e-04,  ..., -9.4040e-04,\n",
       "              -5.0692e-04,  1.5769e-03]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[4.6054e-06, 4.6908e-06, 2.9302e-06,  ..., 2.1533e-05, 3.6770e-06,\n",
       "              9.6789e-05],\n",
       "             [8.9687e-06, 1.0915e-05, 6.7364e-06,  ..., 8.0318e-05, 1.0754e-05,\n",
       "              3.9857e-04],\n",
       "             [5.9828e-06, 8.5537e-06, 4.0822e-06,  ..., 4.4904e-05, 6.8932e-06,\n",
       "              2.0179e-04],\n",
       "             ...,\n",
       "             [9.1009e-06, 1.1707e-05, 8.5794e-06,  ..., 9.8941e-05, 1.0691e-05,\n",
       "              4.0234e-04],\n",
       "             [5.0722e-06, 7.2782e-06, 7.6540e-06,  ..., 6.4588e-05, 7.4356e-06,\n",
       "              2.0730e-04],\n",
       "             [4.9536e-06, 7.4522e-06, 4.5872e-06,  ..., 3.9835e-05, 6.4750e-06,\n",
       "              2.0407e-04]], device='cuda:0')},\n",
       "    3: {'step': tensor(1060791.),\n",
       "     'exp_avg': tensor([[ 9.9170e-05, -1.2944e-04,  2.3526e-05,  ...,  2.0128e-05,\n",
       "               3.8003e-06, -1.4292e-04],\n",
       "             [ 3.6257e-07, -6.5496e-06, -7.9669e-08,  ..., -1.1617e-07,\n",
       "              -9.0711e-07, -2.5112e-05],\n",
       "             [ 1.1705e-03, -1.0441e-03,  3.2211e-04,  ...,  1.3343e-03,\n",
       "              -2.1146e-06, -1.2972e-03],\n",
       "             ...,\n",
       "             [ 1.8658e-04,  2.4694e-05,  1.4788e-04,  ...,  8.5333e-04,\n",
       "              -1.3430e-04, -8.8118e-05],\n",
       "             [ 1.5354e-03, -1.0127e-05,  1.1315e-04,  ...,  4.6220e-04,\n",
       "              -5.8937e-05,  5.6544e-04],\n",
       "             [ 7.6237e-04, -1.9238e-03,  2.2787e-04,  ...,  5.8325e-04,\n",
       "               2.1599e-05, -1.1859e-03]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[3.4083e-06, 1.0313e-07, 1.2365e-08,  ..., 2.4892e-07, 3.0545e-08,\n",
       "              1.6728e-06],\n",
       "             [1.2931e-10, 6.3044e-10, 6.9648e-13,  ..., 1.9651e-11, 1.5984e-11,\n",
       "              8.5806e-09],\n",
       "             [5.8490e-05, 5.1712e-05, 7.0467e-06,  ..., 3.4290e-05, 1.6186e-07,\n",
       "              1.4848e-04],\n",
       "             ...,\n",
       "             [1.2227e-03, 1.9585e-07, 1.1771e-04,  ..., 5.8386e-04, 6.3226e-07,\n",
       "              1.0348e-06],\n",
       "             [3.3986e-04, 1.7218e-08, 5.3721e-07,  ..., 1.8161e-05, 1.5899e-06,\n",
       "              7.1078e-05],\n",
       "             [8.5724e-06, 3.7206e-04, 6.0049e-07,  ..., 3.6363e-06, 1.0304e-06,\n",
       "              1.1674e-03]], device='cuda:0')},\n",
       "    4: {'step': tensor(1060791.),\n",
       "     'exp_avg': tensor([[-2.2465e-05, -5.6052e-45, -6.7655e-05,  ..., -2.9631e-05,\n",
       "              -1.9333e-05,  3.3650e-05],\n",
       "             [-3.2697e-06,  5.6052e-45, -9.1646e-06,  ...,  1.8579e-06,\n",
       "              -6.4923e-07, -1.1688e-05],\n",
       "             [ 9.7711e-05,  5.6052e-45,  7.3677e-05,  ...,  3.0992e-05,\n",
       "               3.2996e-05,  5.3216e-05],\n",
       "             ...,\n",
       "             [-4.1842e-05,  5.6052e-45,  2.2438e-05,  ...,  1.5430e-05,\n",
       "              -2.9525e-06,  1.6114e-05],\n",
       "             [-7.2227e-05, -5.6052e-45, -4.7014e-05,  ..., -6.8021e-05,\n",
       "              -3.9567e-05, -8.9629e-06],\n",
       "             [ 2.4823e-04,  5.6052e-45,  8.6252e-04,  ...,  4.4796e-05,\n",
       "              -3.0141e-05,  1.5508e-04]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[7.2236e-08, 7.0065e-43, 4.0615e-07,  ..., 1.0840e-07, 3.4471e-08,\n",
       "              5.6573e-07],\n",
       "             [4.1309e-10, 7.0065e-43, 6.6943e-10,  ..., 6.1461e-11, 6.6222e-11,\n",
       "              9.1109e-10],\n",
       "             [8.8394e-08, 7.0065e-43, 4.7901e-06,  ..., 7.7580e-07, 2.9185e-08,\n",
       "              1.7103e-06],\n",
       "             ...,\n",
       "             [3.6520e-09, 7.0065e-43, 5.3486e-07,  ..., 3.9217e-09, 2.2370e-10,\n",
       "              4.8741e-07],\n",
       "             [1.9859e-07, 7.0065e-43, 2.8939e-07,  ..., 1.1060e-07, 6.2411e-08,\n",
       "              5.9642e-07],\n",
       "             [4.3421e-07, 7.0065e-43, 4.3118e-05,  ..., 1.0717e-07, 1.1687e-07,\n",
       "              1.7535e-05]], device='cuda:0')},\n",
       "    5: {'step': tensor(1060791.),\n",
       "     'exp_avg': tensor([[-2.7673e-05, -5.6052e-45, -2.1021e-04,  ..., -5.6052e-45,\n",
       "              -4.5353e-05, -5.4041e-04],\n",
       "             [-3.3277e-05,  5.6052e-45, -6.8380e-05,  ...,  0.0000e+00,\n",
       "              -9.1096e-06, -6.0071e-05],\n",
       "             [ 6.4341e-06,  5.6052e-45,  4.7933e-05,  ...,  5.6052e-45,\n",
       "               1.4436e-04, -8.3559e-05],\n",
       "             ...,\n",
       "             [-2.7402e-04,  5.6052e-45, -1.6087e-04,  ...,  5.6052e-45,\n",
       "              -2.7736e-05, -1.6676e-04],\n",
       "             [-3.1307e-06,  5.6052e-45,  1.6733e-05,  ..., -5.6052e-45,\n",
       "               4.3599e-06,  1.6450e-04],\n",
       "             [ 2.4543e-05, -5.6052e-45, -2.4456e-05,  ..., -5.6052e-45,\n",
       "               1.1519e-04, -2.5820e-04]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.7862e-07, 7.0065e-43, 1.1706e-06,  ..., 7.0065e-43, 1.1786e-07,\n",
       "              1.8136e-06],\n",
       "             [1.6582e-08, 7.0065e-43, 6.2467e-08,  ..., 0.0000e+00, 1.2627e-09,\n",
       "              7.8699e-08],\n",
       "             [4.8437e-07, 7.0065e-43, 2.3151e-06,  ..., 7.0065e-43, 5.6193e-07,\n",
       "              1.0114e-06],\n",
       "             ...,\n",
       "             [1.4996e-07, 7.0065e-43, 1.5213e-05,  ..., 7.0065e-43, 3.0357e-08,\n",
       "              1.4800e-05],\n",
       "             [2.4238e-07, 7.0065e-43, 3.0069e-07,  ..., 7.0065e-43, 1.6738e-07,\n",
       "              7.2293e-07],\n",
       "             [2.8244e-07, 7.0065e-43, 6.3625e-07,  ..., 7.0065e-43, 1.1666e-07,\n",
       "              1.9084e-06]], device='cuda:0')},\n",
       "    6: {'step': tensor(1060791.),\n",
       "     'exp_avg': tensor([[ 2.5750e-04, -3.0902e-05,  7.1577e-05,  ...,  9.5765e-06,\n",
       "               1.4835e-04,  3.5108e-04],\n",
       "             [-6.4967e-06, -1.3078e-06,  1.4532e-06,  ...,  3.6500e-05,\n",
       "              -3.2718e-05, -1.1399e-04],\n",
       "             [ 1.1606e-05, -7.0241e-05,  4.2295e-06,  ...,  2.0530e-06,\n",
       "              -7.6786e-05,  1.1891e-05],\n",
       "             ...,\n",
       "             [-3.5258e-05, -2.0558e-05,  1.2908e-05,  ...,  1.0233e-04,\n",
       "              -3.8307e-05, -9.7903e-05],\n",
       "             [ 6.4919e-05,  3.2858e-05,  1.2515e-04,  ..., -1.9914e-05,\n",
       "              -1.2090e-05,  2.0951e-04],\n",
       "             [-9.4729e-05, -4.5892e-05,  1.3771e-04,  ..., -8.4736e-06,\n",
       "               9.4375e-05,  3.7350e-05]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.6006e-07, 1.9297e-08, 1.9886e-07,  ..., 1.5533e-08, 1.1213e-07,\n",
       "              5.1314e-07],\n",
       "             [6.2278e-09, 1.4540e-08, 1.5022e-08,  ..., 4.7091e-08, 6.7289e-09,\n",
       "              1.0021e-07],\n",
       "             [3.6522e-08, 1.6008e-08, 1.5784e-07,  ..., 3.9119e-07, 2.9106e-08,\n",
       "              6.1963e-08],\n",
       "             ...,\n",
       "             [3.2358e-08, 6.3665e-08, 2.6913e-07,  ..., 1.4916e-06, 1.2613e-08,\n",
       "              2.3859e-07],\n",
       "             [5.7785e-08, 5.5930e-09, 1.3442e-07,  ..., 1.0421e-07, 4.5673e-08,\n",
       "              1.8093e-07],\n",
       "             [9.6086e-08, 1.8287e-08, 2.9515e-07,  ..., 3.1932e-07, 1.1918e-07,\n",
       "              1.9125e-07]], device='cuda:0')},\n",
       "    7: {'step': tensor(1060791.),\n",
       "     'exp_avg': tensor([[ 5.4654e-05,  1.6008e-05, -3.0992e-06,  ...,  4.4117e-05,\n",
       "               3.3763e-05, -1.1572e-05],\n",
       "             [ 8.8997e-05,  3.5830e-06,  4.0873e-05,  ...,  3.1947e-05,\n",
       "              -7.5905e-05, -1.8087e-06],\n",
       "             [-2.5596e-12, -1.4799e-05, -1.2267e-05,  ...,  6.3757e-05,\n",
       "               3.4472e-05,  3.5002e-05],\n",
       "             ...,\n",
       "             [-4.0327e-05,  6.4123e-06, -3.4662e-05,  ...,  1.5449e-05,\n",
       "              -7.9173e-05, -1.5624e-05],\n",
       "             [ 2.6774e-04, -1.7306e-05,  4.9425e-05,  ...,  7.3790e-06,\n",
       "              -7.0744e-05, -2.4934e-05],\n",
       "             [-1.3510e-03, -4.0875e-05,  1.3090e-04,  ...,  1.7327e-04,\n",
       "              -4.1147e-04, -1.3034e-04]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.9682e-07, 5.2982e-09, 1.8591e-08,  ..., 2.8427e-08, 8.2644e-08,\n",
       "              4.0635e-09],\n",
       "             [2.8338e-07, 2.1652e-09, 1.7416e-08,  ..., 2.3977e-08, 3.9947e-08,\n",
       "              5.7132e-09],\n",
       "             [1.5086e-10, 2.7908e-09, 1.9131e-07,  ..., 1.6484e-07, 1.2256e-07,\n",
       "              2.5826e-08],\n",
       "             ...,\n",
       "             [6.7101e-07, 1.3134e-08, 1.3067e-07,  ..., 1.8233e-07, 3.3854e-07,\n",
       "              4.3016e-08],\n",
       "             [1.7343e-06, 3.2590e-09, 5.2204e-08,  ..., 7.9708e-08, 1.9242e-07,\n",
       "              4.7426e-08],\n",
       "             [3.1051e-05, 1.5387e-07, 1.0226e-06,  ..., 5.8248e-07, 3.9042e-06,\n",
       "              5.2497e-07]], device='cuda:0')}},\n",
       "   'param_groups': [{'lr': 8.827985642843417e-05,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0.0,\n",
       "     'amsgrad': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'capturable': False,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'initial_lr': 0.0007,\n",
       "     'params': [0, 1, 2, 3, 4, 5, 6, 7]}]}],\n",
       " 'lr_schedulers': [{'gamma': 0.985,\n",
       "   'base_lrs': [0.0007],\n",
       "   'last_epoch': 137,\n",
       "   'verbose': False,\n",
       "   '_step_count': 138,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [8.827985642843417e-05]}],\n",
       " 'hparams_name': None,\n",
       " 'hyper_parameters': {'model': {'class_path': 'gnn_tracking.models.graph_construction.GraphConstructionFCNN',\n",
       "   'init_args': {'in_dim': 14,\n",
       "    'hidden_dim': 256,\n",
       "    'out_dim': 8,\n",
       "    'depth': 6,\n",
       "    'beta': 0.4}},\n",
       "  'preproc': None,\n",
       "  'lw_repulsive': 0.06,\n",
       "  'loss_fct': {'class_path': 'gnn_tracking.metrics.losses.GraphConstructionHingeEmbeddingLoss',\n",
       "   'init_args': {'r_emb': 1,\n",
       "    'max_num_neighbors': 256,\n",
       "    'attr_pt_thld': 0.9,\n",
       "    'p_attr': 2.0,\n",
       "    'p_rep': 2.0}},\n",
       "  'gc_scanner': {'class_path': 'gnn_tracking.graph_construction.k_scanner.GraphConstructionKNNScanner',\n",
       "   'init_args': {'ks': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "    'targets': (0.8, 0.85, 0.88, 0.9, 0.93, 0.95, 0.97, 0.99),\n",
       "    'max_radius': 1.0,\n",
       "    'pt_thld': 0.9,\n",
       "    'max_eta': 4.0,\n",
       "    'subsample_pids': None,\n",
       "    'max_edges': 5000000}}},\n",
       " 'datamodule_hparams_name': 'kwargs',\n",
       " 'datamodule_hyper_parameters': {'train': {'dirs': ['/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_1/',\n",
       "    '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_2/',\n",
       "    '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_3/',\n",
       "    '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_4/',\n",
       "    '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_5/',\n",
       "    '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_6/',\n",
       "    '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_7/',\n",
       "    '/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_8/']},\n",
       "  'val': {'dirs': ['/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v6/part_9/'],\n",
       "   'stop': 50},\n",
       "  'test': None,\n",
       "  'cpus': 6}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def make_ckpt_compatible(ckpt):\n",
    "    margs = ckpt[\"hyper_parameters\"]\n",
    "    largs = ckpt[\"hyper_parameters\"][\"loss_fct\"][\"init_args\"]\n",
    "    for key, value in copy.deepcopy(margs).items():\n",
    "        if key.startswith(\"lw_\"):\n",
    "            largs[key] = value\n",
    "            del margs[key]\n",
    "    ckpt[\"hyper_parameters\"] = margs\n",
    "    ckpt[\"hyper_parameters\"][\"loss_fct\"][\"init_args\"] = largs\n",
    "    ckpt[\"hyper_parameters\"][\"loss_fct\"][\"init_args\"][\"pt_thld\"] = ckpt[\"hyper_parameters\"][\"loss_fct\"][\"init_args\"].pop(\"attr_pt_thld\")\n",
    "    ckpt[\"hyper_parameters\"][\"loss_fct\"][\"class_path\"] = ckpt[\"hyper_parameters\"][\"loss_fct\"][\"class_path\"].replace(\"losses\", \"losses.metric_learning\")\n",
    "    ckpt[\"hyper_parameters\"][\"model\"][\"init_args\"][\"alpha\"] = 1-ckpt[\"hyper_parameters\"][\"model\"][\"init_args\"].pop(\"beta\")\n",
    "    return ckpt\n",
    "\n",
    "ckpt = make_ckpt_compatible(ckpt)\n",
    "compat_name = ml_chkpt_path.parent / (ml_chkpt_path.stem + \"_compatible.ckpt\")\n",
    "torch.save(ckpt, compat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'class_path': 'gnn_tracking.models.graph_construction.GraphConstructionFCNN',\n",
       "  'init_args': {'in_dim': 14,\n",
       "   'hidden_dim': 256,\n",
       "   'out_dim': 24,\n",
       "   'depth': 5,\n",
       "   'alpha': 0.5}},\n",
       " 'preproc': None,\n",
       " 'loss_fct': {'class_path': 'gnn_tracking.metrics.losses.metric_learning.GraphConstructionHingeEmbeddingLoss',\n",
       "  'init_args': {'r_emb': 1,\n",
       "   'max_num_neighbors': 256,\n",
       "   'p_attr': 2.0,\n",
       "   'p_rep': 2.0,\n",
       "   'lw_repulsive': 0.006,\n",
       "   'pt_thld': 0.9}},\n",
       " 'gc_scanner': {'class_path': 'gnn_tracking.graph_construction.k_scanner.GraphConstructionKNNScanner',\n",
       "  'init_args': {'ks': [7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
       "   'targets': (0.8, 0.85, 0.88, 0.9, 0.93, 0.95, 0.97, 0.99),\n",
       "   'max_radius': 1.0,\n",
       "   'pt_thld': 0.9,\n",
       "   'max_eta': 4.0,\n",
       "   'subsample_pids': None,\n",
       "   'max_edges': 5000000}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"hyper_parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_path': 'gnn_tracking.models.graph_construction.GraphConstructionFCNN',\n",
       " 'init_args': {'in_dim': 14,\n",
       "  'hidden_dim': 256,\n",
       "  'out_dim': 8,\n",
       "  'depth': 6,\n",
       "  'alpha': 0.4}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(compat_name)[\"hyper_parameters\"][\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'hc_in' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['hc_in'])`.\n",
      "\u001b[36m[11:43:17] DEBUG: Getting class MLModule from module gnn_tracking.training.ml\u001b[0m\n",
      "\u001b[36m[11:43:30] DEBUG: Loading checkpoint /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/model_exchange/gc/quiet-origami-prawn_compatible.ckpt\u001b[0m\n",
      "\u001b[36m[11:43:31] DEBUG: Getting class GraphConstructionFCNN from module gnn_tracking.models.graph_construction\u001b[0m\n",
      "\u001b[36m[11:43:31] DEBUG: Getting class GraphConstructionHingeEmbeddingLoss from module gnn_tracking.metrics.losses.metric_learning\u001b[0m\n",
      "\u001b[36m[11:43:31] DEBUG: Getting class GraphConstructionKNNScanner from module gnn_tracking.graph_construction.k_scanner\u001b[0m\n",
      "\u001b[36m[11:43:31] DEBUG: Checkpoint loaded. Model ready to go.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = PreTrainedECGraphTCN(\n",
    "      ec=None,\n",
    "      node_indim= 38,\n",
    "      edge_indim= 76,\n",
    "      h_dim= 192,\n",
    "      e_dim= 192,\n",
    "      hidden_dim= 192,\n",
    "      h_outdim= 24,\n",
    "      L_hc= 5,\n",
    "      alpha_latent= 0.5,\n",
    "      n_embedding_coords= 24,\n",
    ")\n",
    "preproc = MLGraphConstructionFromChkpt(\n",
    "    ml_chkpt_path=compat_name,\n",
    "    max_num_neighbors= 15,\n",
    "    max_radius= 1.,\n",
    "    use_embedding_features= True,\n",
    "    build_edge_features= True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "condensation_loss = CondensationLossTiger(\n",
    "      q_min= 0.01,\n",
    "      max_n_rep=100_000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensation_loss = CondensationLossRG(\n",
    "      max_num_neighbors=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc = TCModule(\n",
    "    model=model,\n",
    "    preproc=preproc,\n",
    "    loss_fct=condensation_loss,\n",
    "    cluster_scanner=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnn_tracking.utils.loading import TrackingDataModule\n",
    "\n",
    "dm = TrackingDataModule(\n",
    "    identifier=\"point_clouds_v10\",\n",
    "    train=dict(\n",
    "        dirs=[\n",
    "            \"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_1/\"\n",
    "        ],\n",
    "        sample_size=1000,\n",
    "        # If you run into memory issues, reduce this\n",
    "    ),\n",
    "    val=dict(\n",
    "        dirs=[\n",
    "            \"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_9/\"\n",
    "        ],\n",
    "        stop=5\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    callbacks=[PrintValidationMetrics()],\n",
    "    # fast_dev_run=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[32m[11:43:38] INFO: DataLoader will load 900 graphs (out of 900 available).\u001b[0m\n",
      "\u001b[36m[11:43:38] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_1/data21000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_1/data21999_s0.pt\u001b[0m\n",
      "\u001b[32m[11:43:38] INFO: DataLoader will load 5 graphs (out of 1000 available).\u001b[0m\n",
      "\u001b[36m[11:43:38] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_9/data29000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/point_clouds_v8/part_9/data29004_s0.pt\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                 | Params\n",
      "--------------------------------------------------\n",
      "0 | model    | PreTrainedECGraphTCN | 1.9 M \n",
      "1 | preproc  | MLGraphConstruction  | 333 K \n",
      "2 | loss_fct | CondensationLossRG   | 0     \n",
      "--------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "333 K     Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.986     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |                               | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=2` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|              | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Expected feature dimension 38, got 22",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43moc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    994\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1033\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1062\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1059\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    385\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    390\u001b[0m )\n\u001b[0;32m--> 391\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/training/tc.py:86\u001b[0m, in \u001b[0;36mTCModule.validation_step\u001b[0;34m(self, data, batch_idx)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Data, batch_idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preproc(data)\n\u001b[0;32m---> 86\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_preprocessed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     loss, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_losses(out, data)\n\u001b[1;32m     88\u001b[0m     metrics \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_cluster_metrics(out, data, batch_idx)\n",
      "File \u001b[0;32m/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/training/base.py:99\u001b[0m, in \u001b[0;36mTrackingModule.forward\u001b[0;34m(self, data, _preprocessed)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _preprocessed:\n\u001b[1;32m     98\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preproc(data)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/models/track_condensation_networks.py:504\u001b[0m, in \u001b[0;36mPreTrainedECGraphTCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    502\u001b[0m     data: Data,\n\u001b[1;32m    503\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gtcn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/models/track_condensation_networks.py:262\u001b[0m, in \u001b[0;36mModularGraphTCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    260\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(_xs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    261\u001b[0m edge_attrs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(_edge_attrs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 262\u001b[0m \u001b[43massert_feat_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhc_node_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m assert_feat_dim(edge_attrs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhc_edge_encoder\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39minput_size)\n\u001b[1;32m    264\u001b[0m h_hc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhc_node_encoder(x))\n",
      "File \u001b[0;32m~/Documents/23/git_sync/gnn_tracking/src/gnn_tracking/utils/asserts.py:6\u001b[0m, in \u001b[0;36massert_feat_dim\u001b[0;34m(feat_vec, dim)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_feat_dim\u001b[39m(feat_vec: T, dim: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m----> 6\u001b[0m         feat_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m dim\n\u001b[1;32m      7\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected feature dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeat_vec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Expected feature dimension 38, got 22"
     ]
    }
   ],
   "source": [
    "trainer.fit(oc, dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "repo_path = Path(\"/home/kl5675/Documents/23/git_sync/gnn_tracking/tests\")\n",
    "assert repo_path.is_dir()\n",
    "sys.path.append(str(repo_path))\n",
    "\n",
    "\n",
    "from test_losses import generate_test_data\n",
    "\n",
    "from torch import Tensor as T\n",
    "from gnn_tracking.metrics.losses.oc import *\n",
    "from gnn_tracking.metrics.losses.oc import _first_occurrences, _square_distances\n",
    "from torch_cluster import radius_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "tensor([[ 3, 15, 28, 29, 37, 48, 50, 62, 67, 74, 82, 84, 92, 93, 94],\n",
      "        [20, 88, 88, 88, 20, 20, 88, 88, 88, 88, 20, 88, 20, 20, 88]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RG\n",
    "\n",
    "td = generate_test_data(n_nodes=100, n_particles=10, rng=np.random.default_rng(seed=0))\n",
    "beta=td.beta\n",
    "x=td.x\n",
    "particle_id=td.particle_id\n",
    "reconstructable=td.reconstructable\n",
    "pt=td.pt\n",
    "eta=td.eta\n",
    "q_min=0.01\n",
    "radius_threshold=1\n",
    "max_num_neighbors=256\n",
    "\n",
    "mask = get_good_node_mask_tensors(\n",
    "    pt=pt,\n",
    "    particle_id=particle_id,\n",
    "    reconstructable=reconstructable,\n",
    "    eta=eta,\n",
    ")\n",
    "\n",
    "\n",
    "# For better readability, variables that are only relevant in one \"block\"\n",
    "# are prefixed with an underscore\n",
    "# _j means indexed as hits (... x n_hits)\n",
    "# _k means indexed as objects (... x n_objects_of_interest)\n",
    "# _e means indexed by edge\n",
    "# where n_objects_of_interest = len(unique(particle_id[mask]))\n",
    "\n",
    "# -- 1. Determine indices of condensation points (CPs) and q --\n",
    "_sorted_indices_j = torch.argsort(beta, descending=True)\n",
    "_pids_sorted = particle_id[_sorted_indices_j]\n",
    "_alphas = _sorted_indices_j[_first_occurrences(_pids_sorted)]\n",
    "# Index of condensation points in node array\n",
    "# Only particles of interest have CPs, in particular no noise hits or low pt hits \n",
    "alphas_k = _alphas[mask[_alphas]]\n",
    "assert alphas_k.size()[0] > 0, \"No particles found, cannot evaluate loss\"\n",
    "# \"Charge\"\n",
    "q_j = torch.arctanh(beta) ** 2 + q_min\n",
    "assert not torch.isnan(q_j).any(), \"q contains NaNs\"\n",
    "\n",
    "# -- 2. Edges for repulsion loss --\n",
    "_radius_edges = radius_graph(\n",
    "    x=x, r=radius_threshold, max_num_neighbors=max_num_neighbors, loop=False\n",
    ")\n",
    "# Now filter out everything that doesn't include a CP or connects two hits of the\n",
    "# same particle\n",
    "_to_cp_e = torch.isin(_radius_edges[0], alphas_k)\n",
    "_is_repulsive_e = particle_id[_radius_edges[0]] != particle_id[_radius_edges[1]]\n",
    "# Since noise/low pt does not have CPs, they don't repel from each other \n",
    "repulsion_edges_e = _radius_edges[:, _is_repulsive_e & _to_cp_e]\n",
    "\n",
    "# -- 3. Edges for attractive loss --\n",
    "# 1D array (n_nodes): 1 for CPs, 0 otherwise\n",
    "is_cp_j = torch.zeros(len(particle_id), dtype=bool, device=x.device).scatter_(\n",
    "    0, alphas_k, 1\n",
    ")\n",
    "# hit-indices of all non-CPs\n",
    "_non_cp_indices = torch.nonzero(~is_cp_j & mask).squeeze()\n",
    "print(len(_non_cp_indices))\n",
    "# for each non-CP hit, the index of the corresponding CP\n",
    "corresponding_alpha = alphas_k[\n",
    "    torch.searchsorted(particle_id[alphas_k], particle_id[_non_cp_indices])\n",
    "]\n",
    "# Insert alpha indices into their respective positions to form attraction edges\n",
    "attraction_edges_e = torch.stack((\n",
    "    _non_cp_indices,\n",
    "    corresponding_alpha\n",
    "))\n",
    "print(attraction_edges_e)\n",
    "\n",
    "# -- 4. Calculate loss --\n",
    "# Protect against sqrt not being differentiable around 0\n",
    "attraction_distances_e = _square_distances(attraction_edges_e, x)\n",
    "attraction_distances_e\n",
    "attraction_edges_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3, 15, 28, 29, 37, 48, 50, 62, 67, 74, 82, 84, 92, 93, 94])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_non_cp_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3, 15, 28, 29, 37, 48, 50, 62, 67, 74, 82, 84, 92, 93, 94],\n",
       "        [20, 88, 88, 88, 20, 20, 88, 88, 88, 88, 20, 88, 20, 20, 88]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((\n",
    "    torch.nonzero(~is_cp_j & mask).squeeze(),\n",
    "    corresponding_alpha\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3,  0],\n",
      "        [15,  1],\n",
      "        [20,  0],\n",
      "        [28,  1],\n",
      "        [29,  1],\n",
      "        [37,  0],\n",
      "        [48,  0],\n",
      "        [50,  1],\n",
      "        [62,  1],\n",
      "        [67,  1],\n",
      "        [74,  1],\n",
      "        [82,  0],\n",
      "        [84,  1],\n",
      "        [88,  1],\n",
      "        [92,  0],\n",
      "        [93,  0],\n",
      "        [94,  1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = generate_test_data(n_nodes=100, n_particles=10, rng=np.random.default_rng(seed=0))\n",
    "beta=td.beta\n",
    "x=td.x\n",
    "object_id=td.particle_id\n",
    "reconstructable=td.reconstructable\n",
    "pt=td.pt\n",
    "eta=td.eta\n",
    "q_min=0.01\n",
    "radius_threshold=1\n",
    "max_num_neighbors=256\n",
    "noise_threshold=0\n",
    "max_n_rep=0\n",
    "\n",
    "object_mask = get_good_node_mask_tensors(\n",
    "    pt=pt,\n",
    "    particle_id=particle_id,\n",
    "    reconstructable=reconstructable,\n",
    "    eta=eta,\n",
    ")\n",
    "\n",
    "# To protect against nan in divisions\n",
    "eps = 1e-9\n",
    "\n",
    "# x: n_nodes x n_outdim\n",
    "unique_oids = torch.unique(object_id[object_mask])\n",
    "assert len(unique_oids) > 0, \"No particles found, cannot evaluate loss\"\n",
    "# n_nodes x n_pids\n",
    "# The nodes in every column correspond to the hits of a single particle and\n",
    "# should attract each other\n",
    "# Note that a condensation point attracts itself, but since the distance\n",
    "# will be 0, it doesn't matter\n",
    "attractive_mask_jk = object_id.view(-1, 1) == unique_oids.view(1, -1)\n",
    "print(torch.nonzero(attractive_mask_jk))\n",
    "\n",
    "q = torch.arctanh(beta) ** 2 + q_min\n",
    "assert not torch.isnan(q).any(), \"q contains NaNs\"\n",
    "# Index of condensation points in node array\n",
    "alphas_k = torch.argmax(q.view(-1, 1) * attractive_mask_jk, dim=0)\n",
    "\n",
    "# n_objs x n_outdim\n",
    "x_k = x[alphas_k]\n",
    "# 1 x n_objs\n",
    "q_k = q[alphas_k].view(1, -1)\n",
    "\n",
    "dist_j_k = torch.cdist(x, x_k)\n",
    "\n",
    "qw_j_k = q.view(-1, 1) * q_k\n",
    "\n",
    "att_norm_k = (attractive_mask_jk.sum(dim=0) + eps) * len(unique_oids)\n",
    "qw_att = (qw_j_k / att_norm_k)[attractive_mask_jk]\n",
    "\n",
    "# Attractive potential/loss\n",
    "v_att = (qw_att * torch.square(dist_j_k[attractive_mask_jk])).sum()\n",
    "\n",
    "repulsive_mask = (~attractive_mask_jk) & (dist_j_k < 1)\n",
    "n_rep_k = (~attractive_mask_jk).sum(dim=0)\n",
    "n_rep = repulsive_mask.sum()\n",
    "# Don't normalize to repulsive_mask, it includes the dist < 1 count,\n",
    "# (less points within the radius 1 ball should translate to lower loss)\n",
    "rep_norm = (n_rep_k + eps) * len(unique_oids)\n",
    "if n_rep > max_n_rep > 0:\n",
    "    sampling_freq = max_n_rep / n_rep\n",
    "    sampling_mask = (\n",
    "        torch.rand_like(repulsive_mask, dtype=torch.float16) < sampling_freq\n",
    "    )\n",
    "    repulsive_mask &= sampling_mask\n",
    "    rep_norm *= sampling_freq\n",
    "qw_rep = (qw_j_k / rep_norm)[repulsive_mask]\n",
    "v_rep = (qw_rep * (1 - dist_j_k[repulsive_mask])).sum()\n",
    "\n",
    "l_coward = torch.mean(1 - beta[alphas_k])\n",
    "not_noise_j = object_id > noise_threshold\n",
    "l_noise = torch.mean(beta[~not_noise_j])\n",
    "\n",
    "dist_j_k[attractive_mask_jk]\n",
    "attractive_mask_jk.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
