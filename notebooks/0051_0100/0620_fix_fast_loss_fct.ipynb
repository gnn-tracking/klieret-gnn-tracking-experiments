{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix radius graph loss function\n",
    "\n",
    "* **Description**: Backpropagating from Jian's loss function reslts in NaNs in weights. Why?\n",
    "* **Status**:  Active\n",
    "* **Preceeded by**:\n",
    "* **Succeeded by**:\n",
    "* **See also**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/kl5675/micromamba/envs/gnn/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from gnn_tracking.metrics.losses import _first_occurrences, _square_distances\n",
    "import torch\n",
    "\n",
    "from torch import Tensor as T\n",
    "from torch import nn\n",
    "from torch_cluster import radius_graph\n",
    "\n",
    "from gnn_tracking.utils.log import logger\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = Path(\"/home/kl5675/Documents/23/git_sync/gnn_tracking/tests\")\n",
    "assert repo_path.is_dir()\n",
    "sys.path.append(str(repo_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from test_losses import generate_test_data\n",
    "\n",
    "td1 = generate_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 3]), torch.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_orig = torch.rand_like(td1.x, dtype=torch.float)\n",
    "x_orig.shape, x_orig.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gnn_tracking.models.mlp import MLP\n",
    "\n",
    "toy_module = MLP(\n",
    "    input_size=3,\n",
    "    output_size=3,\n",
    "    hidden_dim=3,\n",
    "    L=3,\n",
    "    bias=False\n",
    ")\n",
    "x_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(toy_module.parameters(), lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta=td1.beta\n",
    "particle_id=td1.particle_id\n",
    "q_min=0.01\n",
    "mask=torch.ones_like(td1.beta, dtype=bool)\n",
    "radius_threshold=1\n",
    "max_num_neighbors=500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0611, -0.2563,  0.5765],\n",
       "         [-0.2652, -0.4793,  0.1608],\n",
       "         [ 0.5089, -0.5428, -0.5499]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2008, -0.4391, -0.5297],\n",
       "         [ 0.2972,  0.4742,  0.0300],\n",
       "         [ 0.1287,  0.1871,  0.4061]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0476, -0.5268,  0.4689],\n",
       "         [ 0.2731, -0.3157,  0.0427],\n",
       "         [-0.0703,  0.4760, -0.0117]], requires_grad=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(toy_module.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "x = toy_module(x_orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- 1. Determine indices of condensation points (CPs) and q --\n",
    "_sorted_indices = torch.argsort(beta, descending=True)\n",
    "_pids_sorted = particle_id[_sorted_indices]\n",
    "_alphas = _sorted_indices[_first_occurrences(_pids_sorted)]\n",
    "# Index of condensation points in node array\n",
    "alphas = _alphas[particle_id[_alphas] > 0]\n",
    "assert alphas.size()[0] > 0, \"No particles found, cannot evaluate loss\"\n",
    "q = torch.arctanh(beta) ** 2 + q_min\n",
    "assert not torch.isnan(q).any(), \"q contains NaNs\"\n",
    "\n",
    "# -- 2. Edges for repulsion loss --\n",
    "_radius_edges = radius_graph(\n",
    "    x=x, r=radius_threshold, max_num_neighbors=max_num_neighbors, loop=False\n",
    ")\n",
    "# Now filter out everything that doesn't include a CP or connects two hits of the\n",
    "# same particle\n",
    "_to_cp = torch.isin(_radius_edges[0], alphas)\n",
    "_is_repulsive = particle_id[_radius_edges[0]] != particle_id[_radius_edges[1]]\n",
    "_is_repulsive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# repulsion_edges = _radius_edges[:, _is_repulsive & _to_cp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _square_distances(edges: T, positions: T) -> T:\n",
    "    \"\"\"Returns squared distances between two sets of points\"\"\"\n",
    "    return torch.sum((positions[edges[0]] - positions[edges[1]]) ** 2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# -- 3. Edges for attractive loss --\n",
    "# 1D array (n_nodes): 1 for CPs, 0 otherwise\n",
    "# alpha_hits_filter = torch.zeros(\n",
    "#     len(particle_id), dtype=bool, device=x.device\n",
    "# ).scatter_(0, alphas, 1)\n",
    "# # indices of all non-CPs\n",
    "# non_alpha_indices = torch.arange(len(particle_id), device=x.device)[\n",
    "#     ~alpha_hits_filter\n",
    "# ]\n",
    "\n",
    "# for each non-CP hit, the index of the corresponding CP\n",
    "# alpha_indices = _alphas[\n",
    "#     torch.searchsorted(particle_id[_alphas], particle_id[non_alpha_indices])\n",
    "# ]\n",
    "\n",
    "# Insert alpha indices into their respective positions to form attraction edges\n",
    "# unmasked_attraction_edges = (\n",
    "    # torch.arange(len(particle_id), device=x.device).unsqueeze(0).repeat(2, 1)\n",
    "# )\n",
    "# unmasked_attraction_edges[1, ~alpha_hits_filter] = alpha_indices\n",
    "\n",
    "# Apply mask to attraction edges\n",
    "# attraction_edges = unmasked_attraction_edges[:, mask]\n",
    "\n",
    "# -- 4. Calculate loss --\n",
    "# repulsion_distances = radius_threshold - torch.sqrt(\n",
    "#     _square_distances(_radius_edges, x)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# attraction_distances = _square_distances(attraction_edges, x)\n",
    "\n",
    "# va = attraction_distances * q[attraction_edges[0]] * q[attraction_edges[1]]\n",
    "# vr = repulsion_distances * q[repulsion_edges[0]] * q[repulsion_edges[1]]\n",
    "\n",
    "# assert not torch.isnan(vr).any()\n",
    "# # if torch.isnan(vr).any():\n",
    "#     vr = torch.tensor([[0.0]])\n",
    "#     logger.warning(\"Repulsive loss is NaN\")\n",
    "\n",
    "# a = {\n",
    "#     \"attractive\": (1 / mask.sum()) * torch.sum(va),\n",
    "#     \"repulsive\": (1 / x.size()[0]) * torch.sum(vr),\n",
    "# }\n",
    "loss = torch.sqrt(_square_distances(_radius_edges, x)).mean()# + va.sum()\n",
    "# loss = a[\"attractive\"] + 10*a[\"repulsive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0329, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0611, -0.2563,  0.5765],\n",
       "         [-0.2652, -0.4793,  0.1608],\n",
       "         [ 0.5089, -0.5428, -0.5499]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2008, -0.4391, -0.5296],\n",
       "         [ 0.2972,  0.4742,  0.0300],\n",
       "         [ 0.1287,  0.1871,  0.4061]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]], requires_grad=True)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(toy_module.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "td1 = generate_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 3]), torch.float32)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_orig = torch.rand_like(td1.x, dtype=torch.float)\n",
    "x_orig.shape, x_orig.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gnn_tracking.models.mlp import MLP\n",
    "\n",
    "toy_module = MLP(\n",
    "    input_size=3,\n",
    "    output_size=3,\n",
    "    hidden_dim=3,\n",
    "    L=3,\n",
    "    bias=False\n",
    ")\n",
    "x_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(toy_module.parameters(), lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=torch.ones_like(td1.beta, dtype=bool)\n",
    "radius_threshold=1\n",
    "max_num_neighbors=500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.5678, -0.4374, -0.4212],\n",
       "         [ 0.4101, -0.3442,  0.3485],\n",
       "         [ 0.0829, -0.5078, -0.3383]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.4134, -0.0649,  0.1921],\n",
       "         [-0.4560, -0.1656,  0.3097],\n",
       "         [-0.0355, -0.4623, -0.3310]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.4305, -0.1754,  0.5266],\n",
       "         [ 0.1424, -0.1132,  0.0502],\n",
       "         [-0.4116,  0.1427,  0.1679]], requires_grad=True)]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(toy_module.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 3]), torch.float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_orig = torch.rand_like(td1.x, dtype=torch.float)\n",
    "x_orig.shape, x_orig.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gnn_tracking.models.mlp import MLP\n",
    "\n",
    "toy_module = MLP(\n",
    "    input_size=3,\n",
    "    output_size=3,\n",
    "    hidden_dim=3,\n",
    "    L=3,\n",
    "    bias=False\n",
    ")\n",
    "x_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(toy_module.parameters(), lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=td1.beta\n",
    "particle_id=td1.particle_id\n",
    "q_min=0.01\n",
    "mask=torch.ones_like(td1.beta, dtype=bool)\n",
    "radius_threshold=1\n",
    "max_num_neighbors=500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0611, -0.2563,  0.5765],\n",
       "         [-0.2652, -0.4793,  0.1608],\n",
       "         [ 0.5089, -0.5428, -0.5499]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2008, -0.4391, -0.5297],\n",
       "         [ 0.2972,  0.4742,  0.0300],\n",
       "         [ 0.1287,  0.1871,  0.4061]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0476, -0.5268,  0.4689],\n",
       "         [ 0.2731, -0.3157,  0.0427],\n",
       "         [-0.0703,  0.4760, -0.0117]], requires_grad=True)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list(toy_module.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "x = toy_module(x_orig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([999000])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- 1. Determine indices of condensation points (CPs) and q --\n",
    "_sorted_indices = torch.argsort(beta, descending=True)\n",
    "_pids_sorted = particle_id[_sorted_indices]\n",
    "_alphas = _sorted_indices[_first_occurrences(_pids_sorted)]\n",
    "# Index of condensation points in node array\n",
    "alphas = _alphas[particle_id[_alphas] > 0]\n",
    "assert alphas.size()[0] > 0, \"No particles found, cannot evaluate loss\"\n",
    "q = torch.arctanh(beta) ** 2 + q_min\n",
    "assert not torch.isnan(q).any(), \"q contains NaNs\"\n",
    "\n",
    "# -- 2. Edges for repulsion loss --\n",
    "_radius_edges = radius_graph(\n",
    "    x=x, r=radius_threshold, max_num_neighbors=max_num_neighbors, loop=False\n",
    ")\n",
    "# Now filter out everything that doesn't include a CP or connects two hits of the\n",
    "# same particle\n",
    "_to_cp = torch.isin(_radius_edges[0], alphas)\n",
    "_is_repulsive = particle_id[_radius_edges[0]] != particle_id[_radius_edges[1]]\n",
    "_is_repulsive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repulsion_edges = _radius_edges[:, _is_repulsive & _to_cp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _square_distances(edges: T, positions: T) -> T:\n",
    "    \"\"\"Returns squared distances between two sets of points\"\"\"\n",
    "    return torch.sum((positions[edges[0]] - positions[edges[1]]) ** 2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -- 3. Edges for attractive loss --\n",
    "# 1D array (n_nodes): 1 for CPs, 0 otherwise\n",
    "# alpha_hits_filter = torch.zeros(\n",
    "#     len(particle_id), dtype=bool, device=x.device\n",
    "# ).scatter_(0, alphas, 1)\n",
    "# # indices of all non-CPs\n",
    "# non_alpha_indices = torch.arange(len(particle_id), device=x.device)[\n",
    "#     ~alpha_hits_filter\n",
    "# ]\n",
    "\n",
    "# for each non-CP hit, the index of the corresponding CP\n",
    "# alpha_indices = _alphas[\n",
    "#     torch.searchsorted(particle_id[_alphas], particle_id[non_alpha_indices])\n",
    "# ]\n",
    "\n",
    "# Insert alpha indices into their respective positions to form attraction edges\n",
    "# unmasked_attraction_edges = (\n",
    "    # torch.arange(len(particle_id), device=x.device).unsqueeze(0).repeat(2, 1)\n",
    "# )\n",
    "# unmasked_attraction_edges[1, ~alpha_hits_filter] = alpha_indices\n",
    "\n",
    "# Apply mask to attraction edges\n",
    "# attraction_edges = unmasked_attraction_edges[:, mask]\n",
    "\n",
    "# -- 4. Calculate loss --\n",
    "# repulsion_distances = radius_threshold - torch.sqrt(\n",
    "#     _square_distances(_radius_edges, x)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# attraction_distances = _square_distances(attraction_edges, x)\n",
    "\n",
    "# va = attraction_distances * q[attraction_edges[0]] * q[attraction_edges[1]]\n",
    "# vr = repulsion_distances * q[repulsion_edges[0]] * q[repulsion_edges[1]]\n",
    "\n",
    "# assert not torch.isnan(vr).any()\n",
    "# # if torch.isnan(vr).any():\n",
    "#     vr = torch.tensor([[0.0]])\n",
    "#     logger.warning(\"Repulsive loss is NaN\")\n",
    "\n",
    "# a = {\n",
    "#     \"attractive\": (1 / mask.sum()) * torch.sum(va),\n",
    "#     \"repulsive\": (1 / x.size()[0]) * torch.sum(vr),\n",
    "# }\n",
    "loss = torch.sqrt(_square_distances(_radius_edges, x)).mean()# + va.sum()\n",
    "# loss = a[\"attractive\"] + 10*a[\"repulsive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0329, grad_fn=<MeanBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0611, -0.2563,  0.5765],\n",
       "         [-0.2652, -0.4793,  0.1608],\n",
       "         [ 0.5089, -0.5428, -0.5499]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2008, -0.4391, -0.5296],\n",
       "         [ 0.2972,  0.4742,  0.0300],\n",
       "         [ 0.1287,  0.1871,  0.4061]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]], requires_grad=True)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list(toy_module.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "x = toy_module(x_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "_radius_edges = radius_graph(\n",
    "    x=x, r=radius_threshold, max_num_neighbors=max_num_neighbors, loop=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(_radius_edges[0] - _radius_edges[1]).abs().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x[_radius_edges[0]] - x[_radius_edges[1]]).abs().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0068, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 0\n",
    "loss = torch.sqrt(eps + torch.sum((x[_radius_edges[0]] - x[_radius_edges[1]]) ** 2, dim=-1)).mean()# .mean()# + va.sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3646, -0.2950, -0.5071],\n",
       "         [-0.3415, -0.2405,  0.0264],\n",
       "         [-0.5583,  0.0593,  0.2373]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.5149,  0.3048, -0.5356],\n",
       "         [-0.1742,  0.0945,  0.3880],\n",
       "         [ 0.2685, -0.2282,  0.4230]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]], requires_grad=True)]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "optimizer.step()\n",
    "list(toy_module.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
