{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[20:15:26] INFO: DataLoader will load 28800 graphs (out of 28800 available).\u001B[0m\n",
      "\u001B[36m[20:15:26] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_1/data21000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_1/data21999_s9.pt\u001B[0m\n",
      "\u001B[32m[20:15:27] INFO: DataLoader will load 5 graphs (out of 32000 available).\u001B[0m\n",
      "\u001B[36m[20:15:27] DEBUG: First graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29000_s0.pt, last graph is /scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29000_s12.pt\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from gnn_tracking.utils.loading import TrackingDataModule\n",
    "\n",
    "dm = TrackingDataModule(\n",
    "    train=dict(\n",
    "        dirs=[\n",
    "            \"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_1/\"\n",
    "        ],\n",
    "    ),\n",
    "    val=dict(\n",
    "        dirs=[\n",
    "            \"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/\"\n",
    "        ],\n",
    "        stop=5\n",
    "    ),\n",
    ")\n",
    "dm.setup(stage=\"fit\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch import Tensor as T\n",
    "\n",
    "def get_cc_labels(edge_index: T, num_nodes: int) -> T:\n",
    "\n",
    "    gx = nx.Graph()\n",
    "    gx.add_nodes_from(list(range(num_nodes)))\n",
    "    gx.add_edges_from(edge_index.T.detach().cpu().numpy())\n",
    "    components = nx.connected_components(gx)\n",
    "    index_mapping = {node: index for index,node_set in enumerate(components) for node in node_set}\n",
    "    return T([index_mapping[node] for node in gx.nodes()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "from gnn_tracking.metrics.cluster_metrics import TrackingMetrics, tracking_metrics, \\\n",
    "    tracking_metric_df, ClusterMetricType, _tracking_metrics_nan_results, \\\n",
    "    count_tracking_metrics\n",
    "from typing import Iterable\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def tracking_metrics(\n",
    "    *,\n",
    "    truth: np.ndarray,\n",
    "    predicted: np.ndarray,\n",
    "    pts: np.ndarray,\n",
    "    reconstructable: np.ndarray,\n",
    "    eta: np.ndarray,\n",
    "    pt_thlds: Iterable[float],\n",
    "    predicted_count_thld=3,\n",
    "    max_eta=4,\n",
    ") -> dict[float, TrackingMetrics]:\n",
    "    \"\"\"Calculate 'custom' metrics for matching tracks and hits.\n",
    "\n",
    "    Args:\n",
    "        truth: Truth labels/PIDs for each hit\n",
    "        predicted: Predicted labels/cluster index for each hit. Negative labels are\n",
    "            interpreted as noise (because this is how DBSCAN outputs it) and are\n",
    "            ignored\n",
    "        pts: true pt value of particle belonging to each hit\n",
    "        reconstructable: Whether the hit belongs to a \"reconstructable tracks\" (this\n",
    "            usually implies a cut on the number of layers that are being hit\n",
    "            etc.)\n",
    "        eta: true pseudorapidity of particle belong to each hit\n",
    "        pt_thlds: pt thresholds to calculate the metrics for\n",
    "        predicted_count_thld: Minimal number of hits in a cluster for it to not be\n",
    "            rejected.\n",
    "        max_eta: Maximum eta value to count\n",
    "\n",
    "    Returns:\n",
    "        See `TrackingMetrics`\n",
    "    \"\"\"\n",
    "    for ar in (truth, predicted, pts, reconstructable, eta):\n",
    "        # Tensors behave differently when counting, so this is absolutely vital!\n",
    "        assert isinstance(ar, np.ndarray)\n",
    "    assert predicted.shape == truth.shape == pts.shape, (\n",
    "        predicted.shape,\n",
    "        truth.shape,\n",
    "        pts.shape,\n",
    "        eta.shape,\n",
    "    )\n",
    "    if len(truth) == 0:\n",
    "        return {pt: _tracking_metrics_nan_results for pt in pt_thlds}\n",
    "    pids, counts = np.unique(truth, return_counts=True)\n",
    "    pid2count = dict(zip(pids, counts))\n",
    "    count_ar = np.array([pid2count[pid] for pid in truth])\n",
    "    h_df = pd.DataFrame(\n",
    "        {\n",
    "            \"c\": predicted,\n",
    "            \"id\": truth,\n",
    "            \"pt\": pts,\n",
    "            \"reconstructable\": reconstructable,\n",
    "            \"eta\": eta,\n",
    "            \"n_hits\": count_ar\n",
    "        }\n",
    "    )\n",
    "    c_df = tracking_metric_df(h_df, predicted_count_thld=predicted_count_thld)\n",
    "\n",
    "    result = dict[float, ClusterMetricType]()\n",
    "    for pt in pt_thlds:\n",
    "        c_mask = (\n",
    "            (c_df[\"maj_pt\"] >= pt)\n",
    "            & c_df[\"maj_reconstructable\"]\n",
    "            & (c_df[\"maj_eta\"].abs() < max_eta)\n",
    "            & c_df[\"valid_cluster\"]\n",
    "        )\n",
    "        h_mask = (\n",
    "            (h_df[\"pt\"] >= pt)\n",
    "            & h_df[\"reconstructable\"].astype(bool)\n",
    "            & (h_df[\"eta\"].abs() < max_eta)\n",
    "            & (h_df[\"n_hits\"] >= predicted_count_thld)\n",
    "        )\n",
    "\n",
    "        r = count_tracking_metrics(c_df, h_df, c_mask, h_mask)\n",
    "        result[pt] = r  # type: ignore\n",
    "    return c_df, result  # type: ignore\n",
    "\n",
    "\n",
    "def tracking_metrics_data(data: Data, labels, pt_thlds: Iterable[float],\n",
    "    predicted_count_thld=3,\n",
    "    max_eta=4,):\n",
    "    return tracking_metrics(\n",
    "        truth=data.particle_id.detach().cpu().numpy(),\n",
    "        predicted=labels,\n",
    "        pts=data.pt.detach().cpu().numpy(),\n",
    "        reconstructable=data.reconstructable.detach().cpu().numpy(),\n",
    "        eta=data.eta.detach().cpu().numpy(),\n",
    "        pt_thlds=pt_thlds,\n",
    "        max_eta=max_eta,\n",
    "        predicted_count_thld=predicted_count_thld,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def get_best_truth_metrics(data):\n",
    "    ei = data.edge_index\n",
    "    y = data.y.bool()\n",
    "    tl = get_cc_labels(ei[:, y], num_nodes=data.num_nodes).long()\n",
    "    return tracking_metrics_data(data, tl.detach().cpu().numpy(), [0.9])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from gnn_tracking.analysis.graphs import get_largest_segment_fracs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "data = dm.datasets[\"train\"][0]\n",
    "data.y = data.y.bool()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Set\n",
    "from gnn_tracking.utils.graph_masks import get_good_node_mask\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_largest_segment_fracs(\n",
    "    data: Data,\n",
    "    *,\n",
    "    pt_thld=0.9,\n",
    "    n_particles_sampled=None,\n",
    "    max_eta=4,\n",
    "    count_thld=0,\n",
    ") :\n",
    "    \"\"\"A fast way to get the fraction of hits in the largest segment for each particle.\n",
    "\n",
    "    Args:\n",
    "        data:\n",
    "        pt_thld:\n",
    "        n_particles_sampled: If not None, only consider a subsample of the particles.\n",
    "            This speeds up calculation but introduces statistical fluctuations.\n",
    "        max_eta: Maximum pseudorapidity\n",
    "        count_thld: Minimum size of segment to be considered.\n",
    "\n",
    "    Returns:\n",
    "        Array of fractions.\n",
    "    \"\"\"\n",
    "    # This implementation simply looks at the connected components for a graph\n",
    "    # with all true edges stripped (so connected component = segment).\n",
    "    basic_hit_mask = get_good_node_mask(data, pt_thld=pt_thld, max_eta=max_eta)\n",
    "    unique_pids, counts = torch.unique(\n",
    "        data.particle_id[basic_hit_mask], return_counts=True\n",
    "    )\n",
    "    pid2count = dict(zip(unique_pids.tolist(), counts.tolist()))\n",
    "    if n_particles_sampled is not None:\n",
    "        rand_perm = torch.randperm(len(unique_pids))\n",
    "        unique_pids = unique_pids[rand_perm][:n_particles_sampled]\n",
    "        basic_hit_mask &= torch.isin(data.particle_id, unique_pids)\n",
    "    rdata = Data(\n",
    "        edge_index=data.edge_index[:, data.y],\n",
    "        particle_id=data.particle_id,\n",
    "        num_nodes=len(data.particle_id),\n",
    "    ).subgraph(basic_hit_mask)\n",
    "    gx = nx.Graph()\n",
    "    gx.add_edges_from(rdata.edge_index.T.detach().cpu().numpy())\n",
    "    segments: list[Set[int]] = nx.connected_components(gx)\n",
    "    pid_to_largest_segment = defaultdict(int)\n",
    "    for segment in segments:\n",
    "        if len(segment) < count_thld:\n",
    "            continue\n",
    "        # PID is the same for all nodes in connected component by construction\n",
    "        pid = rdata.particle_id[next(iter(segment))].item()\n",
    "        assert (rdata.particle_id[list(segment)] == pid).all()\n",
    "        pid_to_largest_segment[pid] = max(\n",
    "            pid_to_largest_segment[pid], len(segment) / pid2count[pid]\n",
    "        )\n",
    "    return pid_to_largest_segment, np.array(list(pid_to_largest_segment.values()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "                maj_pid  maj_hits  cluster_size  valid_cluster  \\\nc                                                                \n364  247700453406539776         3             3           True   \n739  247700453406539776         4             4           True   \n\n     maj_reconstructable   maj_eta    maj_pt  maj_pid_hits  maj_frac  \\\nc                                                                      \n364                  1.0  2.433346  0.915068             7       1.0   \n739                  1.0  2.433346  0.915068             7       1.0   \n\n     maj_pid_frac  perfect_match  double_majority  lhc_match  \nc                                                             \n364      0.428571          False            False       True  \n739      0.571429          False             True       True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>maj_pid</th>\n      <th>maj_hits</th>\n      <th>cluster_size</th>\n      <th>valid_cluster</th>\n      <th>maj_reconstructable</th>\n      <th>maj_eta</th>\n      <th>maj_pt</th>\n      <th>maj_pid_hits</th>\n      <th>maj_frac</th>\n      <th>maj_pid_frac</th>\n      <th>perfect_match</th>\n      <th>double_majority</th>\n      <th>lhc_match</th>\n    </tr>\n    <tr>\n      <th>c</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>364</th>\n      <td>247700453406539776</td>\n      <td>3</td>\n      <td>3</td>\n      <td>True</td>\n      <td>1.0</td>\n      <td>2.433346</td>\n      <td>0.915068</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>0.428571</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>739</th>\n      <td>247700453406539776</td>\n      <td>4</td>\n      <td>4</td>\n      <td>True</td>\n      <td>1.0</td>\n      <td>2.433346</td>\n      <td>0.915068</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>0.571429</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf[cdf[\"maj_pid\"] == 247700453406539776]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "{0.9: {'n_particles': 68,\n  'n_cleaned_clusters': 70,\n  'perfect': 0.8676470588235294,\n  'double_majority': 0.9411764705882353,\n  'lhc': 1.0,\n  'fake_perfect': 0.16176470588235295,\n  'fake_double_majority': 0.08823529411764706,\n  'fake_lhc': 0.0}}"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf, mtrx = get_best_truth_metrics(data)\n",
    "mtrx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "lfdct, lsf = get_largest_segment_fracs(data, count_thld=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "65"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lfdct)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9411764705882353"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lsf > 0.5).sum() / 68"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "for pid in lfdct:\n",
    "    if lfdct[pid] <= 0.5:\n",
    "        continue\n",
    "    sel = cdf[cdf[\"maj_pid\"] == pid]\n",
    "    if len(sel) == 0:\n",
    "        print(1, pid)\n",
    "    if not sel[\"double_majority\"].any():\n",
    "        print(2, pid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fixme: Reconstructable doesn't have the count >= 3 cut in it?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check sector PID overlap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "base_path = Path(\"/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "example_data = list(base_path.glob(\"data29004_*\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s28.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s30.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s2.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s21.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s15.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s18.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s26.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s4.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s0.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s7.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s5.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s20.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s23.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s1.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s16.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s24.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s11.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s8.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s27.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s25.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s10.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s3.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s22.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s12.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s9.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s14.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s19.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s17.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s31.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s6.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s29.pt'),\n PosixPath('/scratch/gpfs/IOJALVO/gnn-tracking/object_condensation/graphs_v5/part_9/data29004_s13.pt')]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "seen = set()\n",
    "overlapped = set()\n",
    "for p in example_data:\n",
    "    data = torch.load(p)\n",
    "    new = set(torch.unique(data.particle_id).tolist())\n",
    "    overlapped |= seen & new\n",
    "    seen |= new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6560659599528857"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overlapped) / len(seen)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
